{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.data.utilities as utils\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DATASETS ##\n",
    "# 1. Sentencing data 2017–21 (from: https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1076592/Data-behind-interactive-tools-3.zip)\n",
    "cols = ['Police Force Area', 'Year', 'Sex', 'Age group', 'Offence group', 'Sentence Outcome', 'Custodial Sentence Length','Sentenced']\n",
    "df = utils.loadData(\"data/external/sentencing.csv\", cols=cols)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Court outcomes by police force area 2009–2019 (from: https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/888561/csvs-behind-data-tools-2-2019.zip)\n",
    "cols_2009 =['Police Force Area', 'Year of Appearance', 'Sex', 'Age Group', 'Offence Group', 'Outcome', 'Custodial Sentence Length','Count'] \n",
    "df_2009 = utils.loadData('data/external/court-outcomes-by-PFA-2019.csv', cols=cols_2009)\n",
    "df_2009.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping duplicate data from 2009 dataset that also appears in df\n",
    "filt = df_2009['Year of Appearance'] < 2017\n",
    "df_2009 = df_2009[filt].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = utils.dataframeList(locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardising variable names\n",
    "for data in df_list:\n",
    "    utils.lcColumns(data)\n",
    "    utils.renameColumns(data, columns={\n",
    "        'year_of_appearance': 'year',\n",
    "        'offence_group': 'offence',\n",
    "        'police_force_area': 'pfa',\n",
    "        'sentence_outcome': 'outcome',\n",
    "        'custodial_sentence_length': 'sentence_length',\n",
    "        'sentenced': 'freq',\n",
    "        'count': 'freq'}\n",
    "        )\n",
    "    # utils.orderColumns(data, column_order = ['year', 'pfa', 'sex', 'age_group', 'offence', 'outcome', 'sentence_length', 'freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tidy_elements(data):\n",
    "    regex = {r\"^\\S*: \\S* - \": \"\",\n",
    "             r\"\\d\\d: \": \"\",\n",
    "            \"Total \": \"\",\n",
    "            \"(Over)\": \"More than\",\n",
    "            \"( and including)\": \"\",\n",
    "            \"(to less than)\": \"and under\",\n",
    "            \"Life$\": \"Life sentence\"\n",
    "             }\n",
    "    return data.map(regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat(df_list)\n",
    "tidy_elements(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat(df_list)\n",
    "utils.tidy_elements(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_dict = {'outcome': \"category\",\n",
    "                'sentence_length': \"category\"\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = df_combined.astype(convert_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/interim/PFA_2009-21_women_cust_comm_sus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = df['outcome'] == 'Immediate custody'\n",
    "pfa_custody_sentence_lengths = df[filt].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfa_custody_sentence_lengths"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining sentence length categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "less_6months = [\"Up to 1 month\", \n",
    "                \"More than 1 month and up to 2 months\",\n",
    "                \"More than 2 months and up to 3 months\",\n",
    "                \"More than 3 months and under 6 months\"]\n",
    "\n",
    "six_12_months = [\"6 months\",\n",
    "                \"More than 6 months and up to 9 months\",\n",
    "                \"More than 9 months and under 12 months\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_length_groups(sentence_len):\n",
    "    if sentence_len in less_6months:\n",
    "        return 'Less than 6 months'\n",
    "    elif sentence_len in six_12_months:\n",
    "        return '6 months and under 12 months'\n",
    "    else:\n",
    "        return 'Over 12 months'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_sentence_lengths(x_df, fill_map):\n",
    "    res=x_df.loc[:,'sentence_len'].map(fill_map)\n",
    "    x_df.loc[:,'sentence_len']=res \n",
    "    \n",
    "    return x_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .query('outcome == @sentence_type')\n",
    "    .pipe(replace_sentence_lengths, sentence_length_groups)\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering for custodial sentences and applying the map\n",
    "\n",
    "pfa_custody_sentence_lengths = df.query('outcome == @sentence_type')\n",
    "pfa_custody_sentence_lengths['sentence_len'] = pfa_custody_sentence_lengths['sentence_len'].map(sentence_length_groups)\n",
    "\n",
    "#Grouping dataset\n",
    "pfa_custody_sentence_lengths = pfa_custody_sentence_lengths.groupby(['pfa', 'year', 'sentence_len'], as_index=False)['freq'].sum()\n",
    "\n",
    "#Outputting to CSV\n",
    "pfa_custody_sentence_lengths.to_csv('data/interim/PFA_2009-21_women_cust_sentence_len.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pfa_custody_sentence_lengths.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['sentence_len'] = df2['sentence_len'].map(sentence_length_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['sentence_len'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing cleansed dataset\n",
    "df = pd.read_csv('data/interim/PFA_2009-21_women_cust_comm_sus.csv')\n",
    "\n",
    "## 1.SENTENCING OUTCOME FOR EACH PFA BY YEAR\n",
    "\n",
    "#Grouping dataset\n",
    "pfa_sentencing_outcomes = df.groupby(['pfa', 'year', 'outcome'], as_index=False)['freq'].sum()\n",
    "\n",
    "#Outputting to CSV\n",
    "pfa_sentencing_outcomes.to_csv('data/processed/PFA_2009-21_women_sentencing_outcomes_FINAL.csv', index=False)\n",
    "\n",
    "\n",
    "## 2.CUSTODIAL SENTENCE LENGTHS FOR EACH PFA BY YEAR\n",
    "'''THIS PRODUCES THE DATA FOR FIGURE 1 IN THE PFA FACTSHEET'''\n",
    "\n",
    "#Filtering cleansed dataset\n",
    "filt = df['outcome'] == 'Immediate custody'\n",
    "pfa_custody_sentence_lengths = df[filt].copy()\n",
    "\n",
    "#Defining sentence_len categories\n",
    "less_6months = [\"Up to 1 month\", \n",
    "                \"More than 1 month and up to 2 months\",\n",
    "                \"More than 2 months and up to 3 months\",\n",
    "                \"More than 3 months and under 6 months\"]\n",
    "\n",
    "six_12_months = [\"6 months\",\n",
    "                \"More than 6 months and up to 9 months\",\n",
    "                \"More than 9 months and under 12 months\"]\n",
    "\n",
    "#Mapping sentence_len categories\n",
    "def sentence_length_groups(sentence_len):\n",
    "    if sentence_len in less_6months:\n",
    "        return 'Less than 6 months'\n",
    "    elif sentence_len in six_12_months:\n",
    "        return '6 months and under 12 months'\n",
    "    else:\n",
    "        return 'Over 12 months'\n",
    "    \n",
    "pfa_custody_sentence_lengths['sentence_len'] = pfa_custody_sentence_lengths['sentence_len'].map(sentence_length_groups)\n",
    "\n",
    "#Grouping dataset\n",
    "pfa_custody_sentence_lengths = pfa_custody_sentence_lengths.groupby(['pfa', 'year', 'sentence_len'], as_index=False)['freq'].sum()\n",
    "\n",
    "#Outputting to CSV\n",
    "# final_df.to_csv('data/interim/PFA_2009-21_women_cust_sentence_len_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#By year\n",
    "filt = pfa_custody_sentence_lengths['year'] >= 2014\n",
    "pfa_df_2014 = pfa_custody_sentence_lengths[filt].copy()\n",
    "\n",
    "#By sentences of less than six months\n",
    "filt = pfa_df_2014['sentence_len'] == \"Less than 6 months\"\n",
    "lt_6 = pfa_df_2014[filt].copy()\n",
    "\n",
    "#By sentences of less than 12 months\n",
    "filt = pfa_df_2014['sentence_len'] != \"Over 12 months\"\n",
    "lt_12m = pfa_df_2014[filt].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_sentences(df):\n",
    "    new_df = pd.crosstab(index=df['pfa'], columns=df['year'],\n",
    "                        values=df['freq'], aggfunc='sum')\n",
    "    \n",
    "    new_df = new_df.fillna(0.0).astype(int)\n",
    "    new_df['per_change_2014'] = new_df.pct_change(axis='columns', periods=7).dropna(axis='columns')\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt_12m.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_sentences(lt_12m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/interim/PFA_2009-21_women_cust_comm_sus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .groupby(['pfa', 'year', 'outcome'], as_index=False)['freq'].sum()\n",
    "    .to_csv('data/processed/PFA_2009-21_women_sentencing_outcomes_TEST.csv', index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_type = 'Immediate custody'\n",
    "year = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosstab(index, columns, values=None, aggfunc=None):\n",
    "    return pd.crosstab(index, columns, values=values, aggfunc=aggfunc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following publication of new dataset, testing existing `data_processing.py` script logic to ensure QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.data.utilities as utils\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing cleansed dataset\n",
    "df = pd.read_csv('data/interim/PFA_2009-22_women_cust_comm_sus.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.SENTENCING OUTCOME FOR EACH PFA BY YEAR\n",
    "\n",
    "#Grouping dataset and saving out\n",
    "(\n",
    "    df\n",
    "    .groupby(['pfa', 'year', 'outcome'], as_index=False)['freq'].sum()\n",
    "    .to_csv('data/processed/PFA_2009-22_women_sentencing_outcomes_FINAL.csv', index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. CUSTODIAL SENTENCES FOR EACH PFA BY OFFENCE TYPE\n",
    "\n",
    "#Filtering cleansed dataset and grouping by PFA and offence group \n",
    "sentence_type = 'Immediate custody'\n",
    "year = 2022\n",
    "\n",
    "pfa_custody = (\n",
    "    df\n",
    "    .query(\"outcome == @sentence_type & year == @year\")\n",
    "    .groupby(['pfa', 'offence'], as_index=False)['freq'].sum()\n",
    ")\n",
    "\n",
    "#Using crosstab with normalize argument to calculate offence group proportions by PFA\n",
    "pfa_custody_offences = pd.crosstab(index=pfa_custody['pfa'], columns=pfa_custody['offence'], values=pfa_custody['freq'], aggfunc=sum, normalize='index').round(3)\n",
    "\n",
    "#Outputting to CSV\n",
    "pfa_custody_offences.to_csv('data/processed/PFA_2022_offences.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentence_length'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.CUSTODIAL SENTENCE LENGTHS FOR EACH PFA BY YEAR\n",
    "'''THIS PRODUCES THE DATA FOR FIGURE 1 IN THE PFA FACTSHEET'''\n",
    "\n",
    "#Defining sentence_len categories\n",
    "less_6months = [\"Up to 1 month\", \n",
    "                \"More than 1 month and up to 2 months\",\n",
    "                \"More than 2 months and up to 3 months\",\n",
    "                \"More than 3 months and under 6 months\"]\n",
    "\n",
    "six_12_months = [\"6 months\",\n",
    "                \"More than 6 months and up to 9 months\",\n",
    "                \"More than 9 months and under 12 months\"]\n",
    "\n",
    "#Mapping sentence_len categories\n",
    "def sentence_length_groups(sentence_len):\n",
    "    if sentence_len in less_6months:\n",
    "        return 'Less than 6 months'\n",
    "    elif sentence_len in six_12_months:\n",
    "        return '6 months and under 12 months'\n",
    "    else:\n",
    "        return 'Over 12 months'\n",
    "\n",
    "#Filtering for custodial sentences and applying the map\n",
    "\n",
    "pfa_custody_sentence_lengths = df.query('outcome == @sentence_type').copy()\n",
    "pfa_custody_sentence_lengths['sentence_length'] = pfa_custody_sentence_lengths['sentence_length'].map(sentence_length_groups)\n",
    "\n",
    "#Grouping dataset\n",
    "pfa_custody_sentence_lengths = pfa_custody_sentence_lengths.groupby(['pfa', 'year', 'sentence_length'], as_index=False)['freq'].sum()\n",
    "\n",
    "#Outputting to CSV\n",
    "pfa_custody_sentence_lengths.to_csv('data/interim/PFA_2009-22_women_cust_sentence_length.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. CUSTODIAL SENTENCES FOR EACH PFA BY YEAR\n",
    "\n",
    "'''THIS PRODUCES THREE DATASETS: \n",
    "    * TOTAL NUMBER OF WOMEN SENTENCED TO CUSTODY BY PFA; AND OF THOSE \n",
    "        * SENTENCED TO LESS THAN SIX MONTHS; AND\n",
    "        * SENTENCED TO LESS THAN 12 MONTHS'''\n",
    "\n",
    "#FILTERING DATA\n",
    "\n",
    "#By year\n",
    "filt = pfa_custody_sentence_lengths['year'] >= 2014\n",
    "pfa_df_2014 = pfa_custody_sentence_lengths[filt].copy()\n",
    "\n",
    "#By sentences of less than six months\n",
    "filt = pfa_df_2014['sentence_length'] == \"Less than 6 months\"\n",
    "lt_6m = pfa_df_2014[filt].copy()\n",
    "\n",
    "#By sentences of less than 12 months\n",
    "filt = pfa_df_2014['sentence_length'] != \"Over 12 months\"\n",
    "lt_12m = pfa_df_2014[filt].copy()\n",
    "\n",
    "#Defining new function for aggregating data and adding a percentage change column\n",
    "def aggregate_sentences(df):\n",
    "    new_df = pd.crosstab(index=df['pfa'], columns=df['year'],\n",
    "                        values=df['freq'], aggfunc='sum')\n",
    "    \n",
    "    new_df = new_df.fillna(0.0).astype(int)\n",
    "    new_df['per_change_2014'] = new_df.pct_change(axis='columns', periods=8).dropna(axis='columns')\n",
    "    return new_df\n",
    "\n",
    "#Using dictionary comprehension to run both DataFrames through the function\n",
    "'''This returns a new dictionary df_dict with _table added to the keys. Values can be accessed using df_dict['key'] and DataFrame functionality is retained\n",
    "See https://stackoverflow.com/questions/51845732/apply-a-function-to-multiple-dataframes-return-multiple-dfs-as-output'''\n",
    "\n",
    "sentence_length_dict = {'cust_sentences_total':pfa_df_2014, 'cust_sentences_lt_6m':lt_6m, 'cust_sentences_lt_12m': lt_12m}\n",
    "df_dict = {i+'_table': aggregate_sentences(sentence_length) for i, sentence_length in sentence_length_dict.items()}\n",
    "\n",
    "#Outputting to CSV\n",
    "#These are the final versions ready for formatting and publication\n",
    "for i, df in df_dict.items():\n",
    "    df.to_csv(f'data/processed/UPDATED{i}.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the output of these tables for consistency against earlier dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df = pd.read_csv(\"data/processed/UPDATEDcust_sentences_total_table.csv\")\n",
    "updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_csv(\"data/processed/cust_sentences_total_table.csv\")\n",
    "original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = ['2022', 'per_change_2014']\n",
    "updated_df.drop(drop, axis=1, inplace=True)\n",
    "original_df.drop(['per_change_2014'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df.compare(original_df, align_axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a difference of one in only two PFA 2017 cases. As before I suspect this is simply a data revision, the difference is so minor.\n",
    "\n",
    "Let's also compare the sentence length data produced at stage 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_csv(\"data/interim/PFA_2009-21_women_cust_sentence_len.csv\")\n",
    "original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df = pd.read_csv(\"data/interim/PFA_2009-22_women_cust_sentence_length.csv\")\n",
    "updated_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out the 2022 values from `updated_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = updated_df['year'] != 2022\n",
    "updated_df = updated_df[filt].copy()\n",
    "updated_df = updated_df.reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming the `sentence_len` column in `original_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df.rename(columns={'sentence_len': \"sentence_length\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df.sort_index(inplace=True)\n",
    "updated_df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df.compare(updated_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting to get a bit confused here. There appear to be two additional rows in the `updated_df` which I suspect are what is causing this error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_df.columns, updated_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df['sentence_length'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_count = pd.crosstab(index=updated_df['pfa'], columns=['year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_count = pd.crosstab(index=original_df['pfa'], columns=['year'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now compare these two crosstabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_count.compare(updated_count, align_axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right, so there are a few differences here. Let's check these out further.\n",
    "\n",
    "First there's one fewer entry in the `updated_df` for Cleveland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df.query('pfa == \"Cleveland\"').groupby(['year']).size() == updated_df.query('pfa == \"Cleveland\"').groupby(['year']).size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right, that appears to be in 2014, which is a little odd. Let's see what the difference is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfa = 'Cleveland'\n",
    "year = 2014\n",
    "for df in [original_df, updated_df]:\n",
    "    print(df.query('pfa == @pfa & year == @year'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whilst at first glance the difference in values is a bit concerning. It's worth noting that the totals are broadly the same 90 vs 91. Let's dig into this a bit further by revisiting some earlier versions of this data.\n",
    "\n",
    "Starting by looking at some of the `nan` and `24:not known` entries within `sentence_length`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentence_length'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_type = 'Immediate custody'\n",
    "df.query('outcome == @sentence_type & sentence_length == \"24:not known\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('outcome == @sentence_type & sentence_length.isnull()')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, well it's not that. Let's dig into the count of the unconsolidated sentence lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleveland = df.query('pfa == \"Cleveland\" & outcome == @sentence_type').copy()\n",
    "cleveland"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping 2022 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleveland = df.query('pfa == \"Cleveland\" & outcome == @sentence_type & year < 2022').copy()\n",
    "cleveland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleveland.groupby(['year', 'sentence_length'], as_index=False)['freq'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in 2021 equivalent dataset\n",
    "df_2021 = pd.read_csv('data/interim/PFA_2009-21_women_cust_comm_sus.csv')\n",
    "df_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleveland_2021 = df_2021.query('pfa == \"Cleveland\" & outcome == @sentence_type').copy()\n",
    "cleveland_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleveland_2021.groupby(['year'])['freq'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleveland.groupby(['year'])['freq'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleveland_2021.groupby(['sentence_len'])['freq'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleveland.groupby(['sentence_length'])['freq'].sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aha, there's some weirdness going on with the `sentence_lengths`. There are some which say they are \"under\" and others that say they are \"up to\". Let's see which years include these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleveland.query('sentence_length == \"More than 3 months and up to 6 months\"')['year'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think this is a newly introduced issue by wording change in the 2010 data onwards. Let's circle back to the importation of the original datasets and see whether the issue lies there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.data.utilities as utils\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"data/external/obo_sent_pivot_2010_2022/\"\n",
    "all_files = glob.glob(path + \"*.csv\")\n",
    "\n",
    "\n",
    "## IMPORTING DATASETS ##\n",
    "# 1. Sentencing data 2010–22 \n",
    "# (from: https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1157979/obo_sent_pivot_2010_2015.zip and \n",
    "# https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1157991/obo_sent_pivot_2016_2022.zip)\n",
    "\n",
    "cols = ['Police Force Area', 'Year', 'Sex', 'Age group', 'Offence group', 'Sentence Outcome', 'Custodial Sentence Length','Sentenced']\n",
    "all_csvs = [utils.loadData(filename, cols=cols) for filename in all_files]\n",
    "df = pd.concat(all_csvs, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df['Custodial Sentence Length'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right, there is a clear difference in the naming convention here, \"and including\" is specific and this is missing in the 6 month, 12 month and 4 years entries. Let's check that my regex work isn't causing the issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's perform the column transformations first to make filtering the dataset more straightforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns\n",
    "utils.lcColumns(df)\n",
    "utils.renameColumns(df, columns={\n",
    "    'year_of_appearance': 'year',\n",
    "    'offence_group': 'offence',\n",
    "    'police_force_area': 'pfa',\n",
    "    'sentence_outcome': 'outcome',\n",
    "    'custodial_sentence_length': 'sentence_length',\n",
    "    'sentenced': 'freq',\n",
    "    'count': 'freq'}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using my `tidy_elements()` function to double check the impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.tidy_elements(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df['sentence_length'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right, so my regex is losing that subtlety for those three groups, so I need to adjust this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done, and re-run the above code with that element of the regex removed. Now to switch back to `2022_data_match_testing.ipynb` to see if I can output the data as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right, `PFA_2010-22_women_cust_comm_sus.csv` has now been output. Let's attempt this again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.data.utilities as utils\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>pfa</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_group</th>\n",
       "      <th>offence</th>\n",
       "      <th>outcome</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>Female</td>\n",
       "      <td>Young adults</td>\n",
       "      <td>Violence against the person</td>\n",
       "      <td>Community sentence</td>\n",
       "      <td>24:Not known</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>Female</td>\n",
       "      <td>Young adults</td>\n",
       "      <td>Drug offences</td>\n",
       "      <td>Community sentence</td>\n",
       "      <td>24:Not known</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>Female</td>\n",
       "      <td>Young adults</td>\n",
       "      <td>Violence against the person</td>\n",
       "      <td>Immediate custody</td>\n",
       "      <td>Life sentence</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>Female</td>\n",
       "      <td>Young adults</td>\n",
       "      <td>Violence against the person</td>\n",
       "      <td>Community sentence</td>\n",
       "      <td>24:Not known</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>Female</td>\n",
       "      <td>Young adults</td>\n",
       "      <td>Violence against the person</td>\n",
       "      <td>Suspended sentence</td>\n",
       "      <td>24:Not known</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                pfa     sex     age_group                      offence  \\\n",
       "0  2010  Avon and Somerset  Female  Young adults  Violence against the person   \n",
       "1  2010  Avon and Somerset  Female  Young adults                Drug offences   \n",
       "2  2010  Avon and Somerset  Female  Young adults  Violence against the person   \n",
       "3  2010  Avon and Somerset  Female  Young adults  Violence against the person   \n",
       "4  2010  Avon and Somerset  Female  Young adults  Violence against the person   \n",
       "\n",
       "              outcome sentence_length  freq  \n",
       "0  Community sentence    24:Not known     1  \n",
       "1  Community sentence    24:Not known     1  \n",
       "2   Immediate custody   Life sentence     1  \n",
       "3  Community sentence    24:Not known     1  \n",
       "4  Suspended sentence    24:Not known     1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing cleansed dataset\n",
    "df = pd.read_csv('data/interim/PFA_2010-22_women_cust_comm_sus.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.SENTENCING OUTCOME FOR EACH PFA BY YEAR\n",
    "\n",
    "#Grouping dataset and saving out\n",
    "(\n",
    "    df\n",
    "    .groupby(['pfa', 'year', 'outcome'], as_index=False)['freq'].sum()\n",
    "    .to_csv('data/processed/PFA_2010-22_women_sentencing_outcomes_FINAL.csv', index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pfa</th>\n",
       "      <th>year</th>\n",
       "      <th>outcome</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2010</td>\n",
       "      <td>Community sentence</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2010</td>\n",
       "      <td>Immediate custody</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2010</td>\n",
       "      <td>Suspended sentence</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2011</td>\n",
       "      <td>Community sentence</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2011</td>\n",
       "      <td>Immediate custody</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pfa  year             outcome  freq\n",
       "0  Avon and Somerset  2010  Community sentence   618\n",
       "1  Avon and Somerset  2010   Immediate custody   173\n",
       "2  Avon and Somerset  2010  Suspended sentence   164\n",
       "3  Avon and Somerset  2011  Community sentence   732\n",
       "4  Avon and Somerset  2011   Immediate custody   206"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.groupby(['pfa', 'year', 'outcome'], as_index=False)['freq'].sum()\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pfa</th>\n",
       "      <th>year</th>\n",
       "      <th>outcome</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Cleveland</td>\n",
       "      <td>2016</td>\n",
       "      <td>Community sentence</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Cleveland</td>\n",
       "      <td>2016</td>\n",
       "      <td>Immediate custody</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Cleveland</td>\n",
       "      <td>2016</td>\n",
       "      <td>Suspended sentence</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Cleveland</td>\n",
       "      <td>2017</td>\n",
       "      <td>Community sentence</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Cleveland</td>\n",
       "      <td>2017</td>\n",
       "      <td>Immediate custody</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Cleveland</td>\n",
       "      <td>2017</td>\n",
       "      <td>Suspended sentence</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Cleveland</td>\n",
       "      <td>2018</td>\n",
       "      <td>Community sentence</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Cleveland</td>\n",
       "      <td>2018</td>\n",
       "      <td>Immediate custody</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Cleveland</td>\n",
       "      <td>2018</td>\n",
       "      <td>Suspended sentence</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Cleveland</td>\n",
       "      <td>2019</td>\n",
       "      <td>Community sentence</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Cleveland</td>\n",
       "      <td>2019</td>\n",
       "      <td>Immediate custody</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Cleveland</td>\n",
       "      <td>2019</td>\n",
       "      <td>Suspended sentence</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pfa  year             outcome  freq\n",
       "174  Cleveland  2016  Community sentence   341\n",
       "175  Cleveland  2016   Immediate custody   108\n",
       "176  Cleveland  2016  Suspended sentence   175\n",
       "177  Cleveland  2017  Community sentence   335\n",
       "178  Cleveland  2017   Immediate custody   152\n",
       "179  Cleveland  2017  Suspended sentence   183\n",
       "180  Cleveland  2018  Community sentence   368\n",
       "181  Cleveland  2018   Immediate custody   140\n",
       "182  Cleveland  2018  Suspended sentence   125\n",
       "183  Cleveland  2019  Community sentence   306\n",
       "184  Cleveland  2019   Immediate custody    98\n",
       "185  Cleveland  2019  Suspended sentence    95"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.query('pfa == \"Cleveland\" & 2020 > year > 2015')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checked these values against previously published edition of Cleveland factsheet and the data is spot on. \n",
    "\n",
    "Let's move on to the next output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. CUSTODIAL SENTENCES FOR EACH PFA BY OFFENCE TYPE\n",
    "\n",
    "#Filtering cleansed dataset and grouping by PFA and offence group \n",
    "sentence_type = 'Immediate custody'\n",
    "year = 2022\n",
    "\n",
    "pfa_custody = (\n",
    "    df\n",
    "    .query(\"outcome == @sentence_type & year == @year\")\n",
    "    .groupby(['pfa', 'offence'], as_index=False)['freq'].sum()\n",
    ")\n",
    "\n",
    "#Using crosstab with normalize argument to calculate offence group proportions by PFA\n",
    "pfa_custody_offences = pd.crosstab(index=pfa_custody['pfa'], columns=pfa_custody['offence'], values=pfa_custody['freq'], aggfunc=sum, normalize='index').round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>offence</th>\n",
       "      <th>Criminal damage and arson</th>\n",
       "      <th>Drug offences</th>\n",
       "      <th>Fraud Offences</th>\n",
       "      <th>Miscellaneous crimes against society</th>\n",
       "      <th>Possession of weapons</th>\n",
       "      <th>Public order offences</th>\n",
       "      <th>Robbery</th>\n",
       "      <th>Sexual offences</th>\n",
       "      <th>Summary motoring</th>\n",
       "      <th>Summary non-motoring</th>\n",
       "      <th>Theft offences</th>\n",
       "      <th>Violence against the person</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pfa</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Avon and Somerset</th>\n",
       "      <td>0.017</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bedfordshire</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cambridgeshire</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cheshire</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cleveland</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cumbria</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Derbyshire</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Devon and Cornwall</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dorset</th>\n",
       "      <td>0.043</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Durham</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dyfed-Powys</th>\n",
       "      <td>0.050</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Essex</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gloucestershire</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greater Manchester</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gwent</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hampshire</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hertfordshire</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humberside</th>\n",
       "      <td>0.017</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kent</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lancashire</th>\n",
       "      <td>0.017</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leicestershire</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lincolnshire</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Merseyside</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metropolitan Police</th>\n",
       "      <td>0.009</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Norfolk</th>\n",
       "      <td>0.056</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Wales</th>\n",
       "      <td>0.023</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Yorkshire</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Northamptonshire</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Northumbria</th>\n",
       "      <td>0.018</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nottinghamshire</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Wales</th>\n",
       "      <td>0.006</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Yorkshire</th>\n",
       "      <td>0.037</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Staffordshire</th>\n",
       "      <td>0.013</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Suffolk</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surrey</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sussex</th>\n",
       "      <td>0.016</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thames Valley</th>\n",
       "      <td>0.007</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Warwickshire</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Mercia</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Midlands</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Yorkshire</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wiltshire</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "offence              Criminal damage and arson  Drug offences  Fraud Offences  \\\n",
       "pfa                                                                             \n",
       "Avon and Somerset                        0.017          0.103           0.017   \n",
       "Bedfordshire                             0.000          0.079           0.000   \n",
       "Cambridgeshire                           0.000          0.118           0.044   \n",
       "Cheshire                                 0.014          0.122           0.108   \n",
       "Cleveland                                0.010          0.080           0.030   \n",
       "Cumbria                                  0.000          0.069           0.000   \n",
       "Derbyshire                               0.000          0.057           0.057   \n",
       "Devon and Cornwall                       0.000          0.032           0.032   \n",
       "Dorset                                   0.043          0.174           0.130   \n",
       "Durham                                   0.000          0.000           0.000   \n",
       "Dyfed-Powys                              0.050          0.050           0.000   \n",
       "Essex                                    0.000          0.217           0.076   \n",
       "Gloucestershire                          0.000          0.130           0.130   \n",
       "Greater Manchester                       0.020          0.080           0.055   \n",
       "Gwent                                    0.000          0.000           0.000   \n",
       "Hampshire                                0.000          0.057           0.091   \n",
       "Hertfordshire                            0.000          0.023           0.159   \n",
       "Humberside                               0.017          0.109           0.050   \n",
       "Kent                                     0.014          0.063           0.056   \n",
       "Lancashire                               0.017          0.112           0.017   \n",
       "Leicestershire                           0.000          0.114           0.129   \n",
       "Lincolnshire                             0.000          0.043           0.022   \n",
       "Merseyside                               0.015          0.210           0.056   \n",
       "Metropolitan Police                      0.009          0.118           0.047   \n",
       "Norfolk                                  0.056          0.130           0.037   \n",
       "North Wales                              0.023          0.174           0.023   \n",
       "North Yorkshire                          0.000          0.096           0.000   \n",
       "Northamptonshire                         0.000          0.146           0.062   \n",
       "Northumbria                              0.018          0.088           0.035   \n",
       "Nottinghamshire                          0.000          0.083           0.038   \n",
       "South Wales                              0.006          0.158           0.030   \n",
       "South Yorkshire                          0.037          0.084           0.047   \n",
       "Staffordshire                            0.013          0.128           0.077   \n",
       "Suffolk                                  0.000          0.139           0.000   \n",
       "Surrey                                   0.000          0.053           0.000   \n",
       "Sussex                                   0.016          0.194           0.016   \n",
       "Thames Valley                            0.007          0.056           0.042   \n",
       "Warwickshire                             0.000          0.171           0.171   \n",
       "West Mercia                              0.000          0.064           0.106   \n",
       "West Midlands                            0.005          0.028           0.019   \n",
       "West Yorkshire                           0.020          0.056           0.036   \n",
       "Wiltshire                                0.000          0.167           0.000   \n",
       "\n",
       "offence              Miscellaneous crimes against society  \\\n",
       "pfa                                                         \n",
       "Avon and Somerset                                   0.026   \n",
       "Bedfordshire                                        0.053   \n",
       "Cambridgeshire                                      0.015   \n",
       "Cheshire                                            0.014   \n",
       "Cleveland                                           0.060   \n",
       "Cumbria                                             0.000   \n",
       "Derbyshire                                          0.025   \n",
       "Devon and Cornwall                                  0.032   \n",
       "Dorset                                              0.043   \n",
       "Durham                                              0.105   \n",
       "Dyfed-Powys                                         0.100   \n",
       "Essex                                               0.087   \n",
       "Gloucestershire                                     0.043   \n",
       "Greater Manchester                                  0.065   \n",
       "Gwent                                               0.000   \n",
       "Hampshire                                           0.057   \n",
       "Hertfordshire                                       0.136   \n",
       "Humberside                                          0.067   \n",
       "Kent                                                0.091   \n",
       "Lancashire                                          0.112   \n",
       "Leicestershire                                      0.043   \n",
       "Lincolnshire                                        0.043   \n",
       "Merseyside                                          0.072   \n",
       "Metropolitan Police                                 0.082   \n",
       "Norfolk                                             0.019   \n",
       "North Wales                                         0.035   \n",
       "North Yorkshire                                     0.192   \n",
       "Northamptonshire                                    0.042   \n",
       "Northumbria                                         0.105   \n",
       "Nottinghamshire                                     0.045   \n",
       "South Wales                                         0.061   \n",
       "South Yorkshire                                     0.065   \n",
       "Staffordshire                                       0.103   \n",
       "Suffolk                                             0.056   \n",
       "Surrey                                              0.316   \n",
       "Sussex                                              0.000   \n",
       "Thames Valley                                       0.042   \n",
       "Warwickshire                                        0.073   \n",
       "West Mercia                                         0.043   \n",
       "West Midlands                                       0.065   \n",
       "West Yorkshire                                      0.104   \n",
       "Wiltshire                                           0.100   \n",
       "\n",
       "offence              Possession of weapons  Public order offences  Robbery  \\\n",
       "pfa                                                                          \n",
       "Avon and Somerset                    0.009                  0.069    0.009   \n",
       "Bedfordshire                         0.132                  0.053    0.026   \n",
       "Cambridgeshire                       0.059                  0.074    0.015   \n",
       "Cheshire                             0.041                  0.054    0.027   \n",
       "Cleveland                            0.060                  0.020    0.050   \n",
       "Cumbria                              0.000                  0.172    0.000   \n",
       "Derbyshire                           0.025                  0.041    0.025   \n",
       "Devon and Cornwall                   0.111                  0.159    0.000   \n",
       "Dorset                               0.043                  0.000    0.000   \n",
       "Durham                               0.000                  0.070    0.018   \n",
       "Dyfed-Powys                          0.000                  0.100    0.000   \n",
       "Essex                                0.011                  0.011    0.011   \n",
       "Gloucestershire                      0.000                  0.217    0.043   \n",
       "Greater Manchester                   0.020                  0.055    0.025   \n",
       "Gwent                                0.059                  0.235    0.000   \n",
       "Hampshire                            0.011                  0.034    0.023   \n",
       "Hertfordshire                        0.000                  0.068    0.000   \n",
       "Humberside                           0.059                  0.025    0.034   \n",
       "Kent                                 0.007                  0.042    0.021   \n",
       "Lancashire                           0.069                  0.052    0.069   \n",
       "Leicestershire                       0.014                  0.043    0.014   \n",
       "Lincolnshire                         0.022                  0.043    0.022   \n",
       "Merseyside                           0.021                  0.077    0.031   \n",
       "Metropolitan Police                  0.036                  0.066    0.031   \n",
       "Norfolk                              0.037                  0.130    0.019   \n",
       "North Wales                          0.012                  0.081    0.012   \n",
       "North Yorkshire                      0.000                  0.058    0.000   \n",
       "Northamptonshire                     0.042                  0.021    0.042   \n",
       "Northumbria                          0.096                  0.026    0.035   \n",
       "Nottinghamshire                      0.030                  0.030    0.023   \n",
       "South Wales                          0.030                  0.048    0.036   \n",
       "South Yorkshire                      0.047                  0.009    0.037   \n",
       "Staffordshire                        0.051                  0.038    0.026   \n",
       "Suffolk                              0.056                  0.056    0.028   \n",
       "Surrey                               0.000                  0.000    0.000   \n",
       "Sussex                               0.032                  0.016    0.032   \n",
       "Thames Valley                        0.028                  0.091    0.049   \n",
       "Warwickshire                         0.024                  0.024    0.073   \n",
       "West Mercia                          0.000                  0.085    0.000   \n",
       "West Midlands                        0.037                  0.032    0.032   \n",
       "West Yorkshire                       0.052                  0.104    0.012   \n",
       "Wiltshire                            0.033                  0.033    0.000   \n",
       "\n",
       "offence              Sexual offences  Summary motoring  Summary non-motoring  \\\n",
       "pfa                                                                            \n",
       "Avon and Somerset              0.009             0.017                 0.155   \n",
       "Bedfordshire                   0.026             0.000                 0.079   \n",
       "Cambridgeshire                 0.000             0.000                 0.162   \n",
       "Cheshire                       0.000             0.014                 0.095   \n",
       "Cleveland                      0.020             0.030                 0.070   \n",
       "Cumbria                        0.000             0.034                 0.069   \n",
       "Derbyshire                     0.000             0.033                 0.082   \n",
       "Devon and Cornwall             0.048             0.063                 0.095   \n",
       "Dorset                         0.000             0.000                 0.087   \n",
       "Durham                         0.035             0.053                 0.070   \n",
       "Dyfed-Powys                    0.000             0.100                 0.200   \n",
       "Essex                          0.011             0.033                 0.054   \n",
       "Gloucestershire                0.043             0.087                 0.043   \n",
       "Greater Manchester             0.020             0.030                 0.050   \n",
       "Gwent                          0.000             0.059                 0.118   \n",
       "Hampshire                      0.023             0.057                 0.080   \n",
       "Hertfordshire                  0.023             0.000                 0.068   \n",
       "Humberside                     0.017             0.008                 0.101   \n",
       "Kent                           0.007             0.014                 0.077   \n",
       "Lancashire                     0.009             0.017                 0.121   \n",
       "Leicestershire                 0.014             0.000                 0.157   \n",
       "Lincolnshire                   0.065             0.043                 0.065   \n",
       "Merseyside                     0.010             0.010                 0.082   \n",
       "Metropolitan Police            0.005             0.010                 0.111   \n",
       "Norfolk                        0.056             0.000                 0.130   \n",
       "North Wales                    0.012             0.000                 0.128   \n",
       "North Yorkshire                0.019             0.019                 0.115   \n",
       "Northamptonshire               0.000             0.000                 0.104   \n",
       "Northumbria                    0.018             0.009                 0.079   \n",
       "Nottinghamshire                0.023             0.008                 0.068   \n",
       "South Wales                    0.012             0.024                 0.085   \n",
       "South Yorkshire                0.019             0.019                 0.065   \n",
       "Staffordshire                  0.000             0.064                 0.154   \n",
       "Suffolk                        0.028             0.000                 0.083   \n",
       "Surrey                         0.000             0.000                 0.053   \n",
       "Sussex                         0.016             0.048                 0.065   \n",
       "Thames Valley                  0.007             0.007                 0.126   \n",
       "Warwickshire                   0.000             0.000                 0.049   \n",
       "West Mercia                    0.064             0.043                 0.043   \n",
       "West Midlands                  0.005             0.023                 0.056   \n",
       "West Yorkshire                 0.000             0.012                 0.096   \n",
       "Wiltshire                      0.033             0.033                 0.133   \n",
       "\n",
       "offence              Theft offences  Violence against the person  \n",
       "pfa                                                               \n",
       "Avon and Somerset             0.224                        0.345  \n",
       "Bedfordshire                  0.316                        0.237  \n",
       "Cambridgeshire                0.324                        0.191  \n",
       "Cheshire                      0.297                        0.216  \n",
       "Cleveland                     0.410                        0.160  \n",
       "Cumbria                       0.345                        0.310  \n",
       "Derbyshire                    0.443                        0.213  \n",
       "Devon and Cornwall            0.222                        0.206  \n",
       "Dorset                        0.174                        0.304  \n",
       "Durham                        0.421                        0.228  \n",
       "Dyfed-Powys                   0.150                        0.250  \n",
       "Essex                         0.315                        0.174  \n",
       "Gloucestershire               0.130                        0.130  \n",
       "Greater Manchester            0.340                        0.240  \n",
       "Gwent                         0.353                        0.176  \n",
       "Hampshire                     0.284                        0.284  \n",
       "Hertfordshire                 0.341                        0.182  \n",
       "Humberside                    0.294                        0.218  \n",
       "Kent                          0.385                        0.224  \n",
       "Lancashire                    0.216                        0.190  \n",
       "Leicestershire                0.271                        0.200  \n",
       "Lincolnshire                  0.283                        0.348  \n",
       "Merseyside                    0.231                        0.185  \n",
       "Metropolitan Police           0.304                        0.181  \n",
       "Norfolk                       0.241                        0.148  \n",
       "North Wales                   0.349                        0.151  \n",
       "North Yorkshire               0.308                        0.192  \n",
       "Northamptonshire              0.333                        0.208  \n",
       "Northumbria                   0.281                        0.211  \n",
       "Nottinghamshire               0.530                        0.121  \n",
       "South Wales                   0.291                        0.218  \n",
       "South Yorkshire               0.355                        0.215  \n",
       "Staffordshire                 0.154                        0.192  \n",
       "Suffolk                       0.444                        0.111  \n",
       "Surrey                        0.316                        0.263  \n",
       "Sussex                        0.339                        0.226  \n",
       "Thames Valley                 0.301                        0.245  \n",
       "Warwickshire                  0.195                        0.220  \n",
       "West Mercia                   0.298                        0.255  \n",
       "West Midlands                 0.468                        0.231  \n",
       "West Yorkshire                0.315                        0.195  \n",
       "Wiltshire                     0.333                        0.133  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfa_custody_offences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outputting to CSV\n",
    "pfa_custody_offences.to_csv('data/processed/PFA_2022_offences.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentence_length'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating the sentence_length categories with the new wording, after changing my `tidy_elements()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.CUSTODIAL SENTENCE LENGTHS FOR EACH PFA BY YEAR\n",
    "'''THIS PRODUCES THE DATA FOR FIGURE 1 IN THE PFA FACTSHEET'''\n",
    "\n",
    "#Defining sentence_length categories—THESE HAVE BEEN UPDATED\n",
    "less_6months = [\"Up to and including 1 month\", \n",
    "                \"More than 1 month and up to and including 2 months\",\n",
    "                \"More than 2 months and up to and including 3 months\",\n",
    "                \"More than 3 months and up to 6 months\"]\n",
    "\n",
    "six_12_months = [\"6 months\",\n",
    "                \"More than 6 months and up to and including 9 months\",\n",
    "                \"More than 9 months and up to 12 months\"]\n",
    "\n",
    "#Mapping sentence_len categories\n",
    "def sentence_length_groups(sentence_len):\n",
    "    if sentence_len in less_6months:\n",
    "        return 'Less than 6 months'\n",
    "    elif sentence_len in six_12_months:\n",
    "        return '6 months and under 12 months'\n",
    "    else:\n",
    "        return 'Over 12 months'\n",
    "\n",
    "#Filtering for custodial sentences and applying the map\n",
    "\n",
    "pfa_custody_sentence_lengths = df.query('outcome == @sentence_type').copy()\n",
    "pfa_custody_sentence_lengths['sentence_length'] = pfa_custody_sentence_lengths['sentence_length'].map(sentence_length_groups)\n",
    "\n",
    "#Grouping dataset\n",
    "pfa_custody_sentence_lengths = pfa_custody_sentence_lengths.groupby(['pfa', 'year', 'sentence_length'], as_index=False)['freq'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pfa</th>\n",
       "      <th>year</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2010</td>\n",
       "      <td>6 months and under 12 months</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2010</td>\n",
       "      <td>Less than 6 months</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2010</td>\n",
       "      <td>Over 12 months</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2011</td>\n",
       "      <td>6 months and under 12 months</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2011</td>\n",
       "      <td>Less than 6 months</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>2021</td>\n",
       "      <td>Less than 6 months</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>2021</td>\n",
       "      <td>Over 12 months</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>2022</td>\n",
       "      <td>6 months and under 12 months</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>2022</td>\n",
       "      <td>Less than 6 months</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>2022</td>\n",
       "      <td>Over 12 months</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1628 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    pfa  year               sentence_length  freq\n",
       "0     Avon and Somerset  2010  6 months and under 12 months    16\n",
       "1     Avon and Somerset  2010            Less than 6 months   113\n",
       "2     Avon and Somerset  2010                Over 12 months    44\n",
       "3     Avon and Somerset  2011  6 months and under 12 months    21\n",
       "4     Avon and Somerset  2011            Less than 6 months   142\n",
       "...                 ...   ...                           ...   ...\n",
       "1623          Wiltshire  2021            Less than 6 months    15\n",
       "1624          Wiltshire  2021                Over 12 months    15\n",
       "1625          Wiltshire  2022  6 months and under 12 months     5\n",
       "1626          Wiltshire  2022            Less than 6 months    18\n",
       "1627          Wiltshire  2022                Over 12 months     7\n",
       "\n",
       "[1628 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfa_custody_sentence_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pfa</th>\n",
       "      <th>year</th>\n",
       "      <th>sentence_len</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2009</td>\n",
       "      <td>6 months and under 12 months</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2009</td>\n",
       "      <td>Less than 6 months</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2009</td>\n",
       "      <td>Over 12 months</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2010</td>\n",
       "      <td>6 months and under 12 months</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2010</td>\n",
       "      <td>Less than 6 months</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>2020</td>\n",
       "      <td>Less than 6 months</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>2020</td>\n",
       "      <td>Over 12 months</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>2021</td>\n",
       "      <td>6 months and under 12 months</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>2021</td>\n",
       "      <td>Less than 6 months</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>2021</td>\n",
       "      <td>Over 12 months</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1631 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    pfa  year                  sentence_len  freq\n",
       "0     Avon and Somerset  2009  6 months and under 12 months    11\n",
       "1     Avon and Somerset  2009            Less than 6 months   117\n",
       "2     Avon and Somerset  2009                Over 12 months    37\n",
       "3     Avon and Somerset  2010  6 months and under 12 months    16\n",
       "4     Avon and Somerset  2010            Less than 6 months   113\n",
       "...                 ...   ...                           ...   ...\n",
       "1626          Wiltshire  2020            Less than 6 months    15\n",
       "1627          Wiltshire  2020                Over 12 months    13\n",
       "1628          Wiltshire  2021  6 months and under 12 months     3\n",
       "1629          Wiltshire  2021            Less than 6 months    15\n",
       "1630          Wiltshire  2021                Over 12 months    15\n",
       "\n",
       "[1631 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df = pd.read_csv(\"data/interim/PFA_2009-21_women_cust_sentence_len.csv\")\n",
    "original_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop 2009 figures and see if we can `compare()` the two dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pfa</th>\n",
       "      <th>year</th>\n",
       "      <th>sentence_len</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2010</td>\n",
       "      <td>6 months and under 12 months</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2010</td>\n",
       "      <td>Less than 6 months</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2010</td>\n",
       "      <td>Over 12 months</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2011</td>\n",
       "      <td>6 months and under 12 months</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2011</td>\n",
       "      <td>Less than 6 months</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>2020</td>\n",
       "      <td>Less than 6 months</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>2020</td>\n",
       "      <td>Over 12 months</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>2021</td>\n",
       "      <td>6 months and under 12 months</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>2021</td>\n",
       "      <td>Less than 6 months</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>2021</td>\n",
       "      <td>Over 12 months</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1505 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    pfa  year                  sentence_len  freq\n",
       "3     Avon and Somerset  2010  6 months and under 12 months    16\n",
       "4     Avon and Somerset  2010            Less than 6 months   113\n",
       "5     Avon and Somerset  2010                Over 12 months    44\n",
       "6     Avon and Somerset  2011  6 months and under 12 months    21\n",
       "7     Avon and Somerset  2011            Less than 6 months   142\n",
       "...                 ...   ...                           ...   ...\n",
       "1626          Wiltshire  2020            Less than 6 months    15\n",
       "1627          Wiltshire  2020                Over 12 months    13\n",
       "1628          Wiltshire  2021  6 months and under 12 months     3\n",
       "1629          Wiltshire  2021            Less than 6 months    15\n",
       "1630          Wiltshire  2021                Over 12 months    15\n",
       "\n",
       "[1505 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df = original_df.query('year != 2009')\n",
    "original_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's drop 2022 data in `pfa_custody_sentence_lengths`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pfa</th>\n",
       "      <th>year</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2010</td>\n",
       "      <td>6 months and under 12 months</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2010</td>\n",
       "      <td>Less than 6 months</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2010</td>\n",
       "      <td>Over 12 months</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2011</td>\n",
       "      <td>6 months and under 12 months</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2011</td>\n",
       "      <td>Less than 6 months</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>2020</td>\n",
       "      <td>Less than 6 months</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>2020</td>\n",
       "      <td>Over 12 months</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>2021</td>\n",
       "      <td>6 months and under 12 months</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>2021</td>\n",
       "      <td>Less than 6 months</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>2021</td>\n",
       "      <td>Over 12 months</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1505 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    pfa  year               sentence_length  freq\n",
       "0     Avon and Somerset  2010  6 months and under 12 months    16\n",
       "1     Avon and Somerset  2010            Less than 6 months   113\n",
       "2     Avon and Somerset  2010                Over 12 months    44\n",
       "3     Avon and Somerset  2011  6 months and under 12 months    21\n",
       "4     Avon and Somerset  2011            Less than 6 months   142\n",
       "...                 ...   ...                           ...   ...\n",
       "1620          Wiltshire  2020            Less than 6 months    15\n",
       "1621          Wiltshire  2020                Over 12 months    13\n",
       "1622          Wiltshire  2021  6 months and under 12 months     3\n",
       "1623          Wiltshire  2021            Less than 6 months    15\n",
       "1624          Wiltshire  2021                Over 12 months    15\n",
       "\n",
       "[1505 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfa_custody_sentence_lengths = pfa_custody_sentence_lengths.query('year != 2022')\n",
    "pfa_custody_sentence_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, this is a good start, for the first time I've got the same number of rows. Let's investigate whether we can `compare()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kp/698d00016j9g3g0cyrwpwpw00000gn/T/ipykernel_76963/1788724509.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  original_df.rename(columns={'sentence_len': \"sentence_length\"}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "original_df.rename(columns={'sentence_len': \"sentence_length\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = original_df.reset_index(drop=True)\n",
    "pfa_custody_sentence_lengths = pfa_custody_sentence_lengths.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pfa</th>\n",
       "      <th>year</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2010</td>\n",
       "      <td>6 months and under 12 months</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2010</td>\n",
       "      <td>Less than 6 months</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2010</td>\n",
       "      <td>Over 12 months</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2011</td>\n",
       "      <td>6 months and under 12 months</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2011</td>\n",
       "      <td>Less than 6 months</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>2020</td>\n",
       "      <td>Less than 6 months</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>2020</td>\n",
       "      <td>Over 12 months</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>2021</td>\n",
       "      <td>6 months and under 12 months</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>2021</td>\n",
       "      <td>Less than 6 months</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>2021</td>\n",
       "      <td>Over 12 months</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1505 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    pfa  year               sentence_length  freq\n",
       "0     Avon and Somerset  2010  6 months and under 12 months    16\n",
       "1     Avon and Somerset  2010            Less than 6 months   113\n",
       "2     Avon and Somerset  2010                Over 12 months    44\n",
       "3     Avon and Somerset  2011  6 months and under 12 months    21\n",
       "4     Avon and Somerset  2011            Less than 6 months   142\n",
       "...                 ...   ...                           ...   ...\n",
       "1500          Wiltshire  2020            Less than 6 months    15\n",
       "1501          Wiltshire  2020                Over 12 months    13\n",
       "1502          Wiltshire  2021  6 months and under 12 months     3\n",
       "1503          Wiltshire  2021            Less than 6 months    15\n",
       "1504          Wiltshire  2021                Over 12 months    15\n",
       "\n",
       "[1505 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pfa</th>\n",
       "      <th>year</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2010</td>\n",
       "      <td>6 months and under 12 months</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2010</td>\n",
       "      <td>Less than 6 months</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2010</td>\n",
       "      <td>Over 12 months</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2011</td>\n",
       "      <td>6 months and under 12 months</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>2011</td>\n",
       "      <td>Less than 6 months</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>2020</td>\n",
       "      <td>Less than 6 months</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>2020</td>\n",
       "      <td>Over 12 months</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>2021</td>\n",
       "      <td>6 months and under 12 months</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>2021</td>\n",
       "      <td>Less than 6 months</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>2021</td>\n",
       "      <td>Over 12 months</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1505 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    pfa  year               sentence_length  freq\n",
       "0     Avon and Somerset  2010  6 months and under 12 months    16\n",
       "1     Avon and Somerset  2010            Less than 6 months   113\n",
       "2     Avon and Somerset  2010                Over 12 months    44\n",
       "3     Avon and Somerset  2011  6 months and under 12 months    21\n",
       "4     Avon and Somerset  2011            Less than 6 months   142\n",
       "...                 ...   ...                           ...   ...\n",
       "1500          Wiltshire  2020            Less than 6 months    15\n",
       "1501          Wiltshire  2020                Over 12 months    13\n",
       "1502          Wiltshire  2021  6 months and under 12 months     3\n",
       "1503          Wiltshire  2021            Less than 6 months    15\n",
       "1504          Wiltshire  2021                Over 12 months    15\n",
       "\n",
       "[1505 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfa_custody_sentence_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>43.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>46.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     freq      \n",
       "     self other\n",
       "275  43.0  44.0\n",
       "810  46.0  47.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df.compare(pfa_custody_sentence_lengths, align_axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINALLY\n",
    "We have been able to compare and it appears as though there are two additional values in the new dataframe—which matches up with the two additional values in the earlier dataframe `PFA_2010-22_women_cust_comm_sus.csv`. Let's just double check these indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pfa</th>\n",
       "      <th>year</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Devon and Cornwall</td>\n",
       "      <td>2017</td>\n",
       "      <td>Over 12 months</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>Merseyside</td>\n",
       "      <td>2017</td>\n",
       "      <td>Over 12 months</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    pfa  year sentence_length  freq\n",
       "275  Devon and Cornwall  2017  Over 12 months    44\n",
       "810          Merseyside  2017  Over 12 months    47"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfa_custody_sentence_lengths.iloc[[275, 810]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pfa</th>\n",
       "      <th>year</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Devon and Cornwall</td>\n",
       "      <td>2017</td>\n",
       "      <td>Over 12 months</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>Merseyside</td>\n",
       "      <td>2017</td>\n",
       "      <td>Over 12 months</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    pfa  year sentence_length  freq\n",
       "275  Devon and Cornwall  2017  Over 12 months    43\n",
       "810          Merseyside  2017  Over 12 months    46"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df.iloc[[275, 810]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, let's re-run section three with the csv output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.CUSTODIAL SENTENCE LENGTHS FOR EACH PFA BY YEAR\n",
    "'''THIS PRODUCES THE DATA FOR FIGURE 1 IN THE PFA FACTSHEET'''\n",
    "\n",
    "#Defining sentence_length categories—THESE HAVE BEEN UPDATED\n",
    "less_6months = [\"Up to and including 1 month\", \n",
    "                \"More than 1 month and up to and including 2 months\",\n",
    "                \"More than 2 months and up to and including 3 months\",\n",
    "                \"More than 3 months and up to 6 months\"]\n",
    "\n",
    "six_12_months = [\"6 months\",\n",
    "                \"More than 6 months and up to and including 9 months\",\n",
    "                \"More than 9 months and up to 12 months\"]\n",
    "\n",
    "#Mapping sentence_len categories\n",
    "def sentence_length_groups(sentence_len):\n",
    "    if sentence_len in less_6months:\n",
    "        return 'Less than 6 months'\n",
    "    elif sentence_len in six_12_months:\n",
    "        return '6 months and under 12 months'\n",
    "    else:\n",
    "        return 'Over 12 months'\n",
    "\n",
    "#Filtering for custodial sentences and applying the map\n",
    "\n",
    "pfa_custody_sentence_lengths = df.query('outcome == @sentence_type').copy()\n",
    "pfa_custody_sentence_lengths['sentence_length'] = pfa_custody_sentence_lengths['sentence_length'].map(sentence_length_groups)\n",
    "\n",
    "#Grouping dataset\n",
    "pfa_custody_sentence_lengths = pfa_custody_sentence_lengths.groupby(['pfa', 'year', 'sentence_length'], as_index=False)['freq'].sum()\n",
    "\n",
    "#Outputting to CSV\n",
    "pfa_custody_sentence_lengths.to_csv('data/interim/PFA_2010-22_women_cust_sentence_length.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. CUSTODIAL SENTENCES FOR EACH PFA BY YEAR\n",
    "\n",
    "'''THIS PRODUCES THREE DATASETS: \n",
    "    * TOTAL NUMBER OF WOMEN SENTENCED TO CUSTODY BY PFA; AND OF THOSE \n",
    "        * SENTENCED TO LESS THAN SIX MONTHS; AND\n",
    "        * SENTENCED TO LESS THAN 12 MONTHS'''\n",
    "\n",
    "#FILTERING DATA\n",
    "\n",
    "#By year\n",
    "filt = pfa_custody_sentence_lengths['year'] >= 2014\n",
    "pfa_df_2014 = pfa_custody_sentence_lengths[filt].copy()\n",
    "\n",
    "#By sentences of less than six months\n",
    "filt = pfa_df_2014['sentence_length'] == \"Less than 6 months\"\n",
    "lt_6m = pfa_df_2014[filt].copy()\n",
    "\n",
    "#By sentences of less than 12 months\n",
    "filt = pfa_df_2014['sentence_length'] != \"Over 12 months\"\n",
    "lt_12m = pfa_df_2014[filt].copy()\n",
    "\n",
    "#Defining new function for aggregating data and adding a percentage change column\n",
    "def aggregate_sentences(df):\n",
    "    new_df = pd.crosstab(index=df['pfa'], columns=df['year'],\n",
    "                        values=df['freq'], aggfunc='sum')\n",
    "    \n",
    "    new_df = new_df.fillna(0.0).astype(int)\n",
    "    new_df['per_change_2014'] = new_df.pct_change(axis='columns', periods=8).dropna(axis='columns')\n",
    "    return new_df\n",
    "\n",
    "#Using dictionary comprehension to run both DataFrames through the function\n",
    "'''This returns a new dictionary df_dict with _table added to the keys. Values can be accessed using df_dict['key'] and DataFrame functionality is retained\n",
    "See https://stackoverflow.com/questions/51845732/apply-a-function-to-multiple-dataframes-return-multiple-dfs-as-output'''\n",
    "\n",
    "sentence_length_dict = {'cust_sentences_total':pfa_df_2014, 'cust_sentences_lt_6m':lt_6m, 'cust_sentences_lt_12m': lt_12m}\n",
    "df_dict = {i+'_table': aggregate_sentences(sentence_length) for i, sentence_length in sentence_length_dict.items()}\n",
    "\n",
    "#Outputting to CSV\n",
    "#These are the final versions ready for formatting and publication\n",
    "for i, df in df_dict.items():\n",
    "    df.to_csv(f'data/processed/2022_{i}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to compare these 2022 tables with the original tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pfa</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "      <th>per_change_2014</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>196</td>\n",
       "      <td>165</td>\n",
       "      <td>164</td>\n",
       "      <td>158</td>\n",
       "      <td>148</td>\n",
       "      <td>151</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>116</td>\n",
       "      <td>-0.408163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bedfordshire</td>\n",
       "      <td>69</td>\n",
       "      <td>80</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>36</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>38</td>\n",
       "      <td>-0.449275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cambridgeshire</td>\n",
       "      <td>91</td>\n",
       "      <td>89</td>\n",
       "      <td>112</td>\n",
       "      <td>115</td>\n",
       "      <td>116</td>\n",
       "      <td>89</td>\n",
       "      <td>78</td>\n",
       "      <td>47</td>\n",
       "      <td>68</td>\n",
       "      <td>-0.252747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cheshire</td>\n",
       "      <td>169</td>\n",
       "      <td>181</td>\n",
       "      <td>167</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>149</td>\n",
       "      <td>123</td>\n",
       "      <td>117</td>\n",
       "      <td>74</td>\n",
       "      <td>-0.562130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cleveland</td>\n",
       "      <td>91</td>\n",
       "      <td>78</td>\n",
       "      <td>108</td>\n",
       "      <td>152</td>\n",
       "      <td>140</td>\n",
       "      <td>98</td>\n",
       "      <td>55</td>\n",
       "      <td>103</td>\n",
       "      <td>100</td>\n",
       "      <td>0.098901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cumbria</td>\n",
       "      <td>92</td>\n",
       "      <td>103</td>\n",
       "      <td>92</td>\n",
       "      <td>104</td>\n",
       "      <td>132</td>\n",
       "      <td>72</td>\n",
       "      <td>45</td>\n",
       "      <td>40</td>\n",
       "      <td>29</td>\n",
       "      <td>-0.684783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Derbyshire</td>\n",
       "      <td>171</td>\n",
       "      <td>179</td>\n",
       "      <td>176</td>\n",
       "      <td>174</td>\n",
       "      <td>178</td>\n",
       "      <td>123</td>\n",
       "      <td>130</td>\n",
       "      <td>126</td>\n",
       "      <td>122</td>\n",
       "      <td>-0.286550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Devon and Cornwall</td>\n",
       "      <td>116</td>\n",
       "      <td>126</td>\n",
       "      <td>120</td>\n",
       "      <td>148</td>\n",
       "      <td>120</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>86</td>\n",
       "      <td>63</td>\n",
       "      <td>-0.456897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dorset</td>\n",
       "      <td>56</td>\n",
       "      <td>67</td>\n",
       "      <td>52</td>\n",
       "      <td>73</td>\n",
       "      <td>52</td>\n",
       "      <td>61</td>\n",
       "      <td>35</td>\n",
       "      <td>38</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.589286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Durham</td>\n",
       "      <td>82</td>\n",
       "      <td>76</td>\n",
       "      <td>80</td>\n",
       "      <td>64</td>\n",
       "      <td>79</td>\n",
       "      <td>41</td>\n",
       "      <td>56</td>\n",
       "      <td>50</td>\n",
       "      <td>57</td>\n",
       "      <td>-0.304878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dyfed-Powys</td>\n",
       "      <td>37</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>38</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.459459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Essex</td>\n",
       "      <td>198</td>\n",
       "      <td>162</td>\n",
       "      <td>176</td>\n",
       "      <td>176</td>\n",
       "      <td>181</td>\n",
       "      <td>155</td>\n",
       "      <td>91</td>\n",
       "      <td>76</td>\n",
       "      <td>92</td>\n",
       "      <td>-0.535354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Gloucestershire</td>\n",
       "      <td>66</td>\n",
       "      <td>71</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>41</td>\n",
       "      <td>36</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.651515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Greater Manchester</td>\n",
       "      <td>446</td>\n",
       "      <td>402</td>\n",
       "      <td>307</td>\n",
       "      <td>269</td>\n",
       "      <td>217</td>\n",
       "      <td>251</td>\n",
       "      <td>186</td>\n",
       "      <td>182</td>\n",
       "      <td>200</td>\n",
       "      <td>-0.551570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gwent</td>\n",
       "      <td>90</td>\n",
       "      <td>76</td>\n",
       "      <td>88</td>\n",
       "      <td>109</td>\n",
       "      <td>87</td>\n",
       "      <td>40</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.811111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Hampshire</td>\n",
       "      <td>191</td>\n",
       "      <td>207</td>\n",
       "      <td>158</td>\n",
       "      <td>172</td>\n",
       "      <td>158</td>\n",
       "      <td>126</td>\n",
       "      <td>128</td>\n",
       "      <td>100</td>\n",
       "      <td>88</td>\n",
       "      <td>-0.539267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Hertfordshire</td>\n",
       "      <td>92</td>\n",
       "      <td>89</td>\n",
       "      <td>110</td>\n",
       "      <td>101</td>\n",
       "      <td>72</td>\n",
       "      <td>68</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>44</td>\n",
       "      <td>-0.521739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Humberside</td>\n",
       "      <td>154</td>\n",
       "      <td>136</td>\n",
       "      <td>147</td>\n",
       "      <td>122</td>\n",
       "      <td>157</td>\n",
       "      <td>129</td>\n",
       "      <td>137</td>\n",
       "      <td>134</td>\n",
       "      <td>119</td>\n",
       "      <td>-0.227273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Kent</td>\n",
       "      <td>198</td>\n",
       "      <td>189</td>\n",
       "      <td>217</td>\n",
       "      <td>224</td>\n",
       "      <td>193</td>\n",
       "      <td>156</td>\n",
       "      <td>123</td>\n",
       "      <td>135</td>\n",
       "      <td>143</td>\n",
       "      <td>-0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lancashire</td>\n",
       "      <td>234</td>\n",
       "      <td>215</td>\n",
       "      <td>168</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>164</td>\n",
       "      <td>113</td>\n",
       "      <td>147</td>\n",
       "      <td>116</td>\n",
       "      <td>-0.504274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Leicestershire</td>\n",
       "      <td>102</td>\n",
       "      <td>88</td>\n",
       "      <td>95</td>\n",
       "      <td>109</td>\n",
       "      <td>112</td>\n",
       "      <td>95</td>\n",
       "      <td>90</td>\n",
       "      <td>63</td>\n",
       "      <td>70</td>\n",
       "      <td>-0.313725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Lincolnshire</td>\n",
       "      <td>40</td>\n",
       "      <td>52</td>\n",
       "      <td>66</td>\n",
       "      <td>61</td>\n",
       "      <td>73</td>\n",
       "      <td>65</td>\n",
       "      <td>31</td>\n",
       "      <td>43</td>\n",
       "      <td>46</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Merseyside</td>\n",
       "      <td>247</td>\n",
       "      <td>266</td>\n",
       "      <td>265</td>\n",
       "      <td>236</td>\n",
       "      <td>203</td>\n",
       "      <td>213</td>\n",
       "      <td>163</td>\n",
       "      <td>196</td>\n",
       "      <td>195</td>\n",
       "      <td>-0.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Metropolitan Police</td>\n",
       "      <td>1290</td>\n",
       "      <td>1180</td>\n",
       "      <td>1272</td>\n",
       "      <td>1192</td>\n",
       "      <td>998</td>\n",
       "      <td>884</td>\n",
       "      <td>632</td>\n",
       "      <td>536</td>\n",
       "      <td>576</td>\n",
       "      <td>-0.553488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Norfolk</td>\n",
       "      <td>86</td>\n",
       "      <td>98</td>\n",
       "      <td>124</td>\n",
       "      <td>108</td>\n",
       "      <td>98</td>\n",
       "      <td>84</td>\n",
       "      <td>76</td>\n",
       "      <td>62</td>\n",
       "      <td>54</td>\n",
       "      <td>-0.372093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>North Wales</td>\n",
       "      <td>91</td>\n",
       "      <td>106</td>\n",
       "      <td>115</td>\n",
       "      <td>106</td>\n",
       "      <td>111</td>\n",
       "      <td>89</td>\n",
       "      <td>65</td>\n",
       "      <td>79</td>\n",
       "      <td>86</td>\n",
       "      <td>-0.054945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>North Yorkshire</td>\n",
       "      <td>82</td>\n",
       "      <td>78</td>\n",
       "      <td>83</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>95</td>\n",
       "      <td>82</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.365854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Northamptonshire</td>\n",
       "      <td>92</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>62</td>\n",
       "      <td>61</td>\n",
       "      <td>62</td>\n",
       "      <td>36</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>-0.478261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Northumbria</td>\n",
       "      <td>172</td>\n",
       "      <td>177</td>\n",
       "      <td>165</td>\n",
       "      <td>147</td>\n",
       "      <td>141</td>\n",
       "      <td>137</td>\n",
       "      <td>82</td>\n",
       "      <td>108</td>\n",
       "      <td>114</td>\n",
       "      <td>-0.337209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Nottinghamshire</td>\n",
       "      <td>142</td>\n",
       "      <td>167</td>\n",
       "      <td>147</td>\n",
       "      <td>163</td>\n",
       "      <td>171</td>\n",
       "      <td>184</td>\n",
       "      <td>109</td>\n",
       "      <td>105</td>\n",
       "      <td>132</td>\n",
       "      <td>-0.070423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>South Wales</td>\n",
       "      <td>343</td>\n",
       "      <td>327</td>\n",
       "      <td>387</td>\n",
       "      <td>351</td>\n",
       "      <td>362</td>\n",
       "      <td>340</td>\n",
       "      <td>249</td>\n",
       "      <td>243</td>\n",
       "      <td>165</td>\n",
       "      <td>-0.518950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>South Yorkshire</td>\n",
       "      <td>245</td>\n",
       "      <td>229</td>\n",
       "      <td>194</td>\n",
       "      <td>218</td>\n",
       "      <td>153</td>\n",
       "      <td>172</td>\n",
       "      <td>138</td>\n",
       "      <td>98</td>\n",
       "      <td>107</td>\n",
       "      <td>-0.563265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Staffordshire</td>\n",
       "      <td>124</td>\n",
       "      <td>126</td>\n",
       "      <td>113</td>\n",
       "      <td>128</td>\n",
       "      <td>114</td>\n",
       "      <td>132</td>\n",
       "      <td>88</td>\n",
       "      <td>96</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.370968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Suffolk</td>\n",
       "      <td>79</td>\n",
       "      <td>73</td>\n",
       "      <td>49</td>\n",
       "      <td>72</td>\n",
       "      <td>53</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>36</td>\n",
       "      <td>-0.544304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Surrey</td>\n",
       "      <td>90</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>76</td>\n",
       "      <td>44</td>\n",
       "      <td>42</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.788889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Sussex</td>\n",
       "      <td>131</td>\n",
       "      <td>160</td>\n",
       "      <td>129</td>\n",
       "      <td>104</td>\n",
       "      <td>97</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>65</td>\n",
       "      <td>62</td>\n",
       "      <td>-0.526718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Thames Valley</td>\n",
       "      <td>213</td>\n",
       "      <td>255</td>\n",
       "      <td>221</td>\n",
       "      <td>225</td>\n",
       "      <td>194</td>\n",
       "      <td>160</td>\n",
       "      <td>101</td>\n",
       "      <td>142</td>\n",
       "      <td>143</td>\n",
       "      <td>-0.328638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Warwickshire</td>\n",
       "      <td>41</td>\n",
       "      <td>57</td>\n",
       "      <td>60</td>\n",
       "      <td>67</td>\n",
       "      <td>31</td>\n",
       "      <td>46</td>\n",
       "      <td>38</td>\n",
       "      <td>28</td>\n",
       "      <td>41</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>West Mercia</td>\n",
       "      <td>115</td>\n",
       "      <td>102</td>\n",
       "      <td>112</td>\n",
       "      <td>123</td>\n",
       "      <td>107</td>\n",
       "      <td>113</td>\n",
       "      <td>98</td>\n",
       "      <td>62</td>\n",
       "      <td>47</td>\n",
       "      <td>-0.591304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>West Midlands</td>\n",
       "      <td>526</td>\n",
       "      <td>516</td>\n",
       "      <td>555</td>\n",
       "      <td>477</td>\n",
       "      <td>396</td>\n",
       "      <td>406</td>\n",
       "      <td>254</td>\n",
       "      <td>226</td>\n",
       "      <td>216</td>\n",
       "      <td>-0.589354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>West Yorkshire</td>\n",
       "      <td>296</td>\n",
       "      <td>292</td>\n",
       "      <td>335</td>\n",
       "      <td>334</td>\n",
       "      <td>285</td>\n",
       "      <td>301</td>\n",
       "      <td>263</td>\n",
       "      <td>250</td>\n",
       "      <td>251</td>\n",
       "      <td>-0.152027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Wiltshire</td>\n",
       "      <td>32</td>\n",
       "      <td>44</td>\n",
       "      <td>49</td>\n",
       "      <td>47</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>-0.062500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    pfa  2014  2015  2016  2017  2018  2019  2020  2021  2022  \\\n",
       "0     Avon and Somerset   196   165   164   158   148   151   103   103   116   \n",
       "1          Bedfordshire    69    80    53    53    36    31    23    20    38   \n",
       "2        Cambridgeshire    91    89   112   115   116    89    78    47    68   \n",
       "3              Cheshire   169   181   167   172   176   149   123   117    74   \n",
       "4             Cleveland    91    78   108   152   140    98    55   103   100   \n",
       "5               Cumbria    92   103    92   104   132    72    45    40    29   \n",
       "6            Derbyshire   171   179   176   174   178   123   130   126   122   \n",
       "7    Devon and Cornwall   116   126   120   148   120   106   106    86    63   \n",
       "8                Dorset    56    67    52    73    52    61    35    38    23   \n",
       "9                Durham    82    76    80    64    79    41    56    50    57   \n",
       "10          Dyfed-Powys    37    33    32    44    41    38    14    14    20   \n",
       "11                Essex   198   162   176   176   181   155    91    76    92   \n",
       "12      Gloucestershire    66    71    58    58    41    36    18    13    23   \n",
       "13   Greater Manchester   446   402   307   269   217   251   186   182   200   \n",
       "14                Gwent    90    76    88   109    87    40    18    25    17   \n",
       "15            Hampshire   191   207   158   172   158   126   128   100    88   \n",
       "16        Hertfordshire    92    89   110   101    72    68    38    38    44   \n",
       "17           Humberside   154   136   147   122   157   129   137   134   119   \n",
       "18                 Kent   198   189   217   224   193   156   123   135   143   \n",
       "19           Lancashire   234   215   168   198   198   164   113   147   116   \n",
       "20       Leicestershire   102    88    95   109   112    95    90    63    70   \n",
       "21         Lincolnshire    40    52    66    61    73    65    31    43    46   \n",
       "22           Merseyside   247   266   265   236   203   213   163   196   195   \n",
       "23  Metropolitan Police  1290  1180  1272  1192   998   884   632   536   576   \n",
       "24              Norfolk    86    98   124   108    98    84    76    62    54   \n",
       "25          North Wales    91   106   115   106   111    89    65    79    86   \n",
       "26      North Yorkshire    82    78    83    90    88    95    82    52    52   \n",
       "27     Northamptonshire    92    70    78    62    61    62    36    64    48   \n",
       "28          Northumbria   172   177   165   147   141   137    82   108   114   \n",
       "29      Nottinghamshire   142   167   147   163   171   184   109   105   132   \n",
       "30          South Wales   343   327   387   351   362   340   249   243   165   \n",
       "31      South Yorkshire   245   229   194   218   153   172   138    98   107   \n",
       "32        Staffordshire   124   126   113   128   114   132    88    96    78   \n",
       "33              Suffolk    79    73    49    72    53    38    39    42    36   \n",
       "34               Surrey    90    63    63    76    44    42    29    34    19   \n",
       "35               Sussex   131   160   129   104    97    85    66    65    62   \n",
       "36        Thames Valley   213   255   221   225   194   160   101   142   143   \n",
       "37         Warwickshire    41    57    60    67    31    46    38    28    41   \n",
       "38          West Mercia   115   102   112   123   107   113    98    62    47   \n",
       "39        West Midlands   526   516   555   477   396   406   254   226   216   \n",
       "40       West Yorkshire   296   292   335   334   285   301   263   250   251   \n",
       "41            Wiltshire    32    44    49    47    49    49    34    33    30   \n",
       "\n",
       "    per_change_2014  \n",
       "0         -0.408163  \n",
       "1         -0.449275  \n",
       "2         -0.252747  \n",
       "3         -0.562130  \n",
       "4          0.098901  \n",
       "5         -0.684783  \n",
       "6         -0.286550  \n",
       "7         -0.456897  \n",
       "8         -0.589286  \n",
       "9         -0.304878  \n",
       "10        -0.459459  \n",
       "11        -0.535354  \n",
       "12        -0.651515  \n",
       "13        -0.551570  \n",
       "14        -0.811111  \n",
       "15        -0.539267  \n",
       "16        -0.521739  \n",
       "17        -0.227273  \n",
       "18        -0.277778  \n",
       "19        -0.504274  \n",
       "20        -0.313725  \n",
       "21         0.150000  \n",
       "22        -0.210526  \n",
       "23        -0.553488  \n",
       "24        -0.372093  \n",
       "25        -0.054945  \n",
       "26        -0.365854  \n",
       "27        -0.478261  \n",
       "28        -0.337209  \n",
       "29        -0.070423  \n",
       "30        -0.518950  \n",
       "31        -0.563265  \n",
       "32        -0.370968  \n",
       "33        -0.544304  \n",
       "34        -0.788889  \n",
       "35        -0.526718  \n",
       "36        -0.328638  \n",
       "37         0.000000  \n",
       "38        -0.591304  \n",
       "39        -0.589354  \n",
       "40        -0.152027  \n",
       "41        -0.062500  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_total_table = pd.read_csv('data/processed/2022_cust_sentences_total_table.csv')\n",
    "new_total_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the last two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_total_table = new_total_table.drop([\"2022\", \"per_change_2014\" ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pfa</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>196</td>\n",
       "      <td>165</td>\n",
       "      <td>164</td>\n",
       "      <td>158</td>\n",
       "      <td>148</td>\n",
       "      <td>151</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bedfordshire</td>\n",
       "      <td>69</td>\n",
       "      <td>80</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>36</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cambridgeshire</td>\n",
       "      <td>91</td>\n",
       "      <td>89</td>\n",
       "      <td>112</td>\n",
       "      <td>115</td>\n",
       "      <td>116</td>\n",
       "      <td>89</td>\n",
       "      <td>78</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cheshire</td>\n",
       "      <td>169</td>\n",
       "      <td>181</td>\n",
       "      <td>167</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>149</td>\n",
       "      <td>123</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cleveland</td>\n",
       "      <td>91</td>\n",
       "      <td>78</td>\n",
       "      <td>108</td>\n",
       "      <td>152</td>\n",
       "      <td>140</td>\n",
       "      <td>98</td>\n",
       "      <td>55</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pfa  2014  2015  2016  2017  2018  2019  2020  2021\n",
       "0  Avon and Somerset   196   165   164   158   148   151   103   103\n",
       "1       Bedfordshire    69    80    53    53    36    31    23    20\n",
       "2     Cambridgeshire    91    89   112   115   116    89    78    47\n",
       "3           Cheshire   169   181   167   172   176   149   123   117\n",
       "4          Cleveland    91    78   108   152   140    98    55   103"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_total_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pfa</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>per_change_2014</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>196</td>\n",
       "      <td>165</td>\n",
       "      <td>164</td>\n",
       "      <td>158</td>\n",
       "      <td>148</td>\n",
       "      <td>151</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>-0.474490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bedfordshire</td>\n",
       "      <td>69</td>\n",
       "      <td>80</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>36</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.710145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cambridgeshire</td>\n",
       "      <td>91</td>\n",
       "      <td>89</td>\n",
       "      <td>112</td>\n",
       "      <td>115</td>\n",
       "      <td>116</td>\n",
       "      <td>89</td>\n",
       "      <td>78</td>\n",
       "      <td>47</td>\n",
       "      <td>-0.483516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cheshire</td>\n",
       "      <td>169</td>\n",
       "      <td>181</td>\n",
       "      <td>167</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>149</td>\n",
       "      <td>123</td>\n",
       "      <td>117</td>\n",
       "      <td>-0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cleveland</td>\n",
       "      <td>91</td>\n",
       "      <td>78</td>\n",
       "      <td>108</td>\n",
       "      <td>152</td>\n",
       "      <td>140</td>\n",
       "      <td>98</td>\n",
       "      <td>55</td>\n",
       "      <td>103</td>\n",
       "      <td>0.131868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pfa  2014  2015  2016  2017  2018  2019  2020  2021  \\\n",
       "0  Avon and Somerset   196   165   164   158   148   151   103   103   \n",
       "1       Bedfordshire    69    80    53    53    36    31    23    20   \n",
       "2     Cambridgeshire    91    89   112   115   116    89    78    47   \n",
       "3           Cheshire   169   181   167   172   176   149   123   117   \n",
       "4          Cleveland    91    78   108   152   140    98    55   103   \n",
       "\n",
       "   per_change_2014  \n",
       "0        -0.474490  \n",
       "1        -0.710145  \n",
       "2        -0.483516  \n",
       "3        -0.307692  \n",
       "4         0.131868  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_total_table = pd.read_csv('data/processed/cust_sentences_total_table.csv')\n",
    "old_total_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_total_table = old_total_table.drop(\"per_change_2014\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pfa</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>196</td>\n",
       "      <td>165</td>\n",
       "      <td>164</td>\n",
       "      <td>158</td>\n",
       "      <td>148</td>\n",
       "      <td>151</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bedfordshire</td>\n",
       "      <td>69</td>\n",
       "      <td>80</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>36</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cambridgeshire</td>\n",
       "      <td>91</td>\n",
       "      <td>89</td>\n",
       "      <td>112</td>\n",
       "      <td>115</td>\n",
       "      <td>116</td>\n",
       "      <td>89</td>\n",
       "      <td>78</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cheshire</td>\n",
       "      <td>169</td>\n",
       "      <td>181</td>\n",
       "      <td>167</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>149</td>\n",
       "      <td>123</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cleveland</td>\n",
       "      <td>91</td>\n",
       "      <td>78</td>\n",
       "      <td>108</td>\n",
       "      <td>152</td>\n",
       "      <td>140</td>\n",
       "      <td>98</td>\n",
       "      <td>55</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pfa  2014  2015  2016  2017  2018  2019  2020  2021\n",
       "0  Avon and Somerset   196   165   164   158   148   151   103   103\n",
       "1       Bedfordshire    69    80    53    53    36    31    23    20\n",
       "2     Cambridgeshire    91    89   112   115   116    89    78    47\n",
       "3           Cheshire   169   181   167   172   176   149   123   117\n",
       "4          Cleveland    91    78   108   152   140    98    55   103"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_total_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">2017</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>147.0</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>235.0</td>\n",
       "      <td>236.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     2017       \n",
       "     self  other\n",
       "7   147.0  148.0\n",
       "22  235.0  236.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_total_table.compare(new_total_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same observation here of two entries from 2017 with a value of one higher—which is as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pfa</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Devon and Cornwall</td>\n",
       "      <td>116</td>\n",
       "      <td>126</td>\n",
       "      <td>120</td>\n",
       "      <td>148</td>\n",
       "      <td>120</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Merseyside</td>\n",
       "      <td>247</td>\n",
       "      <td>266</td>\n",
       "      <td>265</td>\n",
       "      <td>236</td>\n",
       "      <td>203</td>\n",
       "      <td>213</td>\n",
       "      <td>163</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   pfa  2014  2015  2016  2017  2018  2019  2020  2021\n",
       "7   Devon and Cornwall   116   126   120   148   120   106   106    86\n",
       "22          Merseyside   247   266   265   236   203   213   163   196"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_total_table.iloc[[7, 22]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right, all good. Re-running the consolidated code in one cell now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.data.utilities as utils\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#Importing cleansed dataset\n",
    "df = pd.read_csv('data/interim/PFA_2010-22_women_cust_comm_sus.csv')\n",
    "\n",
    "\n",
    "## 1.SENTENCING OUTCOME FOR EACH PFA BY YEAR\n",
    "\n",
    "#Grouping dataset and saving out\n",
    "(\n",
    "    df\n",
    "    .groupby(['pfa', 'year', 'outcome'], as_index=False)['freq'].sum()\n",
    "    .to_csv('data/processed/PFA_2010-22_women_sentencing_outcomes_FINAL.csv', index=False)\n",
    ")\n",
    "\n",
    "\n",
    "## 2. CUSTODIAL SENTENCES FOR EACH PFA BY OFFENCE TYPE\n",
    "\n",
    "#Filtering cleansed dataset and grouping by PFA and offence group \n",
    "sentence_type = 'Immediate custody'\n",
    "year = 2022\n",
    "\n",
    "pfa_custody = (\n",
    "    df\n",
    "    .query(\"outcome == @sentence_type & year == @year\")\n",
    "    .groupby(['pfa', 'offence'], as_index=False)['freq'].sum()\n",
    ")\n",
    "\n",
    "#Using crosstab with normalize argument to calculate offence group proportions by PFA\n",
    "pfa_custody_offences = pd.crosstab(index=pfa_custody['pfa'], columns=pfa_custody['offence'], values=pfa_custody['freq'], aggfunc=sum, normalize='index').round(3)\n",
    "\n",
    "\n",
    "## 3.CUSTODIAL SENTENCE LENGTHS FOR EACH PFA BY YEAR\n",
    "'''THIS PRODUCES THE DATA FOR FIGURE 1 IN THE PFA FACTSHEET'''\n",
    "\n",
    "#Defining sentence_length categories—THESE HAVE BEEN UPDATED\n",
    "less_6months = [\"Up to and including 1 month\", \n",
    "                \"More than 1 month and up to and including 2 months\",\n",
    "                \"More than 2 months and up to and including 3 months\",\n",
    "                \"More than 3 months and up to 6 months\"]\n",
    "\n",
    "six_12_months = [\"6 months\",\n",
    "                \"More than 6 months and up to and including 9 months\",\n",
    "                \"More than 9 months and up to 12 months\"]\n",
    "\n",
    "#Mapping sentence_len categories\n",
    "def sentence_length_groups(sentence_len):\n",
    "    if sentence_len in less_6months:\n",
    "        return 'Less than 6 months'\n",
    "    elif sentence_len in six_12_months:\n",
    "        return '6 months and under 12 months'\n",
    "    else:\n",
    "        return 'Over 12 months'\n",
    "\n",
    "#Filtering for custodial sentences and applying the map\n",
    "\n",
    "pfa_custody_sentence_lengths = df.query('outcome == @sentence_type').copy()\n",
    "pfa_custody_sentence_lengths['sentence_length'] = pfa_custody_sentence_lengths['sentence_length'].map(sentence_length_groups)\n",
    "\n",
    "#Grouping dataset\n",
    "pfa_custody_sentence_lengths = pfa_custody_sentence_lengths.groupby(['pfa', 'year', 'sentence_length'], as_index=False)['freq'].sum()\n",
    "\n",
    "#Outputting to CSV\n",
    "pfa_custody_sentence_lengths.to_csv('data/interim/PFA_2010-22_women_cust_sentence_length.csv', index=False)\n",
    "\n",
    "\n",
    "## 4. CUSTODIAL SENTENCES FOR EACH PFA BY YEAR\n",
    "\n",
    "'''THIS PRODUCES THREE DATASETS: \n",
    "    * TOTAL NUMBER OF WOMEN SENTENCED TO CUSTODY BY PFA; AND OF THOSE \n",
    "        * SENTENCED TO LESS THAN SIX MONTHS; AND\n",
    "        * SENTENCED TO LESS THAN 12 MONTHS'''\n",
    "\n",
    "#FILTERING DATA\n",
    "\n",
    "#By year\n",
    "filt = pfa_custody_sentence_lengths['year'] >= 2014\n",
    "pfa_df_2014 = pfa_custody_sentence_lengths[filt].copy()\n",
    "\n",
    "#By sentences of less than six months\n",
    "filt = pfa_df_2014['sentence_length'] == \"Less than 6 months\"\n",
    "lt_6m = pfa_df_2014[filt].copy()\n",
    "\n",
    "#By sentences of less than 12 months\n",
    "filt = pfa_df_2014['sentence_length'] != \"Over 12 months\"\n",
    "lt_12m = pfa_df_2014[filt].copy()\n",
    "\n",
    "#Defining new function for aggregating data and adding a percentage change column\n",
    "def aggregate_sentences(df):\n",
    "    new_df = pd.crosstab(index=df['pfa'], columns=df['year'],\n",
    "                        values=df['freq'], aggfunc='sum')\n",
    "    \n",
    "    new_df = new_df.fillna(0.0).astype(int)\n",
    "    new_df['per_change_2014'] = new_df.pct_change(axis='columns', periods=8).dropna(axis='columns')\n",
    "    return new_df\n",
    "\n",
    "#Using dictionary comprehension to run both DataFrames through the function\n",
    "'''This returns a new dictionary df_dict with _table added to the keys. Values can be accessed using df_dict['key'] and DataFrame functionality is retained\n",
    "See https://stackoverflow.com/questions/51845732/apply-a-function-to-multiple-dataframes-return-multiple-dfs-as-output'''\n",
    "\n",
    "sentence_length_dict = {'cust_sentences_total':pfa_df_2014, 'cust_sentences_lt_6m':lt_6m, 'cust_sentences_lt_12m': lt_12m}\n",
    "df_dict = {i+'_table': aggregate_sentences(sentence_length) for i, sentence_length in sentence_length_dict.items()}\n",
    "\n",
    "#Outputting to CSV\n",
    "#These are the final versions ready for formatting and publication\n",
    "for i, df in df_dict.items():\n",
    "    df.to_csv(f'data/processed/2022_{i}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>pfa</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_group</th>\n",
       "      <th>offence</th>\n",
       "      <th>outcome</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>Female</td>\n",
       "      <td>Young adults</td>\n",
       "      <td>Violence against the person</td>\n",
       "      <td>Community sentence</td>\n",
       "      <td>24:Not known</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>Female</td>\n",
       "      <td>Young adults</td>\n",
       "      <td>Drug offences</td>\n",
       "      <td>Community sentence</td>\n",
       "      <td>24:Not known</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>Female</td>\n",
       "      <td>Young adults</td>\n",
       "      <td>Violence against the person</td>\n",
       "      <td>Immediate custody</td>\n",
       "      <td>Life sentence</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>Female</td>\n",
       "      <td>Young adults</td>\n",
       "      <td>Violence against the person</td>\n",
       "      <td>Community sentence</td>\n",
       "      <td>24:Not known</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>Female</td>\n",
       "      <td>Young adults</td>\n",
       "      <td>Violence against the person</td>\n",
       "      <td>Suspended sentence</td>\n",
       "      <td>24:Not known</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                pfa     sex     age_group                      offence  \\\n",
       "0  2010  Avon and Somerset  Female  Young adults  Violence against the person   \n",
       "1  2010  Avon and Somerset  Female  Young adults                Drug offences   \n",
       "2  2010  Avon and Somerset  Female  Young adults  Violence against the person   \n",
       "3  2010  Avon and Somerset  Female  Young adults  Violence against the person   \n",
       "4  2010  Avon and Somerset  Female  Young adults  Violence against the person   \n",
       "\n",
       "              outcome sentence_length  freq  \n",
       "0  Community sentence    24:Not known     1  \n",
       "1  Community sentence    24:Not known     1  \n",
       "2   Immediate custody   Life sentence     1  \n",
       "3  Community sentence    24:Not known     1  \n",
       "4  Suspended sentence    24:Not known     1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csnap(df, fn=lambda x: x.shape, msg=None):\n",
    "    \"\"\" Custom Help function to print things in method chaining.\n",
    "        Returns back the df to further use in chaining.\n",
    "    \"\"\"\n",
    "    if msg:\n",
    "        print(msg)\n",
    "    display(fn(df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pipe(csnap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "women-PFA-outcomes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

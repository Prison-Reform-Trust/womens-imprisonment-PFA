{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development of data processing functions for use in final production script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import src.data.utilities as utils\n",
    "from time import sleep\n",
    "import operator\n",
    "\n",
    "config = utils.read_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(path=config['data']['intFilePath'], filename=\"PFA_2010-22_women_cust_comm_sus.csv\") -> pd.DataFrame:\n",
    "    dfPath=f\"{path}{filename}\"\n",
    "    return pd.read_csv(dfPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = loadData()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categoryColumns(df):      #Converting object columns to category\n",
    "    cols = df.select_dtypes(include='object').columns\n",
    "    for col in cols:\n",
    "        ratio = len(df[col].value_counts()) / len(df)\n",
    "        if ratio < 0.05:\n",
    "            df[col] = df[col].astype('category')\n",
    "    return df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoryColumns(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks as though it's worth doing at this stage as memory usage is around two-thirds less, so let's rewrite the return statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categoryColumns(df) -> pd.DataFrame:\n",
    "    \"\"\"Convert columns to category data type if they meet ratio\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        Processed DataFrame with object columns which meet criteria replaced with categories\n",
    "    \"\"\"\n",
    "    cols = df.select_dtypes(include='object').columns\n",
    "    for col in cols:\n",
    "        ratio = len(df[col].value_counts()) / len(df)\n",
    "        if ratio < 0.05:\n",
    "            df[col] = df[col].astype('category')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as rewriting this to be returned on the loadData function as this will then cascade through the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(status='interim', filename='PFA_2010-22_women_cust_comm_sus.csv') -> pd.DataFrame:\n",
    "    \"\"\"Load CSV file into Pandas DataFrame and convert object columns to categories when they meet criteria in `categoryColumns()`\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    status : {'raw', 'interim', 'processed'}, default is 'interim'\n",
    "        Status of the data processing.\n",
    "        * If 'raw' file is located in \"rawFilePath\" within config file\n",
    "        * If 'interim', file is located in \"intFilePath\"\n",
    "        * If 'processed', file is located in \"clnFilePath\"\n",
    "    filename : str, default is 'PFA_2010-22_women_cust_comm_sus.csv'\n",
    "        Name of CSV file to be loaded.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        CSV data is returned as Pandas DataFrame with any eligible object columns converted into category columns to limit memory requirements\n",
    "    \"\"\"\n",
    "    paths = {\n",
    "        \"raw\": 'rawFilePath',\n",
    "        \"interim\": 'intFilePath',\n",
    "        \"processed\": 'clnFilePath'\n",
    "    }\n",
    "\n",
    "    dfPath=f\"{config['data'][paths[status]]}{filename}\"\n",
    "    df = pd.read_csv(dfPath)\n",
    "    print('Data loaded')\n",
    "    return categoryColumns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = loadData()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveData(df, status, filename, index=True):\n",
    "    \"\"\"Save data during or at the end of a data processing pipeline\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        \n",
    "    status : {'interim', 'processed'}\n",
    "        Status of the data processing. \n",
    "        * If 'interim', file is saved to \"intFilePath\"\n",
    "        * If 'processed', file is saved to \"clnFilePath\"\n",
    "\n",
    "    filename : str\n",
    "        filename parameter for csv export\n",
    "\n",
    "    index : bool\n",
    "        include index of DataFrame in csv output, by default True\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        Render DataFrame as comma-separated file.\n",
    "    \"\"\"\n",
    "    \n",
    "    paths = {\n",
    "            \"interim\": 'intFilePath',\n",
    "            \"processed\": 'clnFilePath'\n",
    "        }\n",
    "    \n",
    "    df.to_csv(f\"{config['data'][paths[status]]}{filename}.csv\", index=index)\n",
    "    print(f\"{filename} saved\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.SENTENCING OUTCOME FOR EACH PFA BY YEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupAndSum(df, columns, sum_column=['freq']):\n",
    "    \"\"\"Perform groupby and sum on a DataFrame\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        _description_\n",
    "    columns : label or list\n",
    "        column names of DataFrame to perform `groupby()` operation\n",
    "    sum_column : label, optional\n",
    "        column name of DataFrame to perform `sum()` operation, by default \"['freq']\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        Reshaped DataFrame grouped by `columns` parameter and the sum of the values over `sum_column`.\n",
    "    \"\"\"\n",
    "    return df.groupby(columns, as_index=False)[sum_column].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentencesByPFA(df, filename=\"sentencesByPFA\"):\n",
    "    \"\"\"Data processing pipeline to produce sentencing outcomes by Police Force Area across\n",
    "    the entire available date range.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "\n",
    "    filename : str, optional\n",
    "        filename parameter for final csv export, by default \"sentencesByPFA\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        Returns the original DataFrame, but saves a fully processed CSV file containing sentencing outcomes by Police Force Area across \n",
    "        the entire available date range.\n",
    "    \"\"\"\n",
    "    my_df = df.copy()\n",
    "\n",
    "    (my_df\n",
    "    .pipe(groupAndSum, columns=['pfa', 'year', 'outcome'])\n",
    "    .pipe(saveData, status='processed', filename=filename, index=False)\n",
    "    )\n",
    "    \n",
    "    #Return original DataFrame to allow for continued processing through the pipeline.\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=loadData()\n",
    "print('Data loaded')\n",
    "sentencesByPFA(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.CUSTODIAL SENTENCES FOR EACH PFA BY OFFENCE TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterSentence(df, sentence_type=None, column='outcome') -> pd.DataFrame:\n",
    "    \"\"\"DataFrame filter allowing selection of subset of data by sentence type\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "\n",
    "    sentence_type : single label or list-like, optional\n",
    "        select from the available sentence types within the DataFrame\n",
    "        {'Community sentence', 'Immediate custody', 'Suspended sentence'}, by default 'Immediate custody'\n",
    "\n",
    "    column : str, optional\n",
    "        column name of DataFrame with sentence outcome values, by default 'outcome'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        A filtered DataFrame displaying the chosen sentence type\n",
    "    \"\"\"\n",
    "    if sentence_type is None:\n",
    "        sentence_type = 'Immediate custody'\n",
    "\n",
    "    mask = None\n",
    "    if type(sentence_type) == str:\n",
    "        mask = df[column] == sentence_type\n",
    "    elif type(sentence_type) == list:\n",
    "        mask = df[column].isin(sentence_type)\n",
    "    \n",
    "    filtered_df = df.loc[mask].copy()\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterYear(df, year=None, op=\"eq\", column='year') -> pd.DataFrame: \n",
    "    \"\"\"DataFrame filter allowing selection of subset of data by year using comparison operators from operator library\n",
    "    Evaluate a comparison operation `=`, `!=`, `>=`, `>`, `<=`, or `<`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        \n",
    "    year : int,\n",
    "        target year, will use the most recent year available in DataFrame if no parameter is provided, default None\n",
    "    op : {eq, ne, gt, ge, lt, le}, optional\n",
    "        comparison operator, by default \"eq\"\n",
    "        lt is equivalent to a < b, \n",
    "        le is equivalent to a <= b, \n",
    "        eq is equivalent to a == b, \n",
    "        ne is equivalent to a != b, \n",
    "        gt is equivalent to a > b and \n",
    "        ge is equivalent to a >= b.\n",
    "    column : str, optional\n",
    "        column name of DataFrame with year values, by default 'year'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        A filtered DataFrame displaying the records for a chosen year or period\n",
    "    \"\"\"\n",
    "\n",
    "    methods = {\n",
    "            \"eq\": operator.eq,\n",
    "            \"ne\": operator.ne,\n",
    "            \"lt\": operator.lt,\n",
    "            \"gt\": operator.gt,\n",
    "            \"le\": operator.le,\n",
    "            \"ge\": operator.ge,\n",
    "        }\n",
    "    if year is None:\n",
    "        mask = methods[op](df[column], df['year'].max())\n",
    "    else:\n",
    "        mask = methods[op](df[column], year)\n",
    "    \n",
    "    filtered_df = df[mask]\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = df.copy()\n",
    "filterYear(my_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = df.copy()\n",
    "filterYear(my_df, 2020, op=\"gt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = df.copy()\n",
    "filterSentence(my_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterSentence(my_df, sentence_type = [\"Suspended sentence\", \"Community sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = df.copy()\n",
    "test_df = (\n",
    "    my_df\n",
    "    .pipe(filterYear, 2020, op=\"ge\")\n",
    "    .pipe(filterSentence)\n",
    "    )\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offenceProportions(df) -> pd.DataFrame:\n",
    "    \"\"\"Calculate proportions of each offence type for each Police Force Area\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        A cross-tabulated DataFrame with float values normalised to each Police Force Area\n",
    "    \"\"\"\n",
    "    return pd.crosstab(index=df['pfa'], \n",
    "                columns=df['offence'], \n",
    "                values=df['freq'], \n",
    "                aggfunc=sum, \n",
    "                normalize='index',\n",
    "                ).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custodialSentencesByOffence(df, filename=None):\n",
    "    \"\"\"Data processing pipeline to produce interim dataset of offence types which received a custodial sentence, by Police Force Area\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "\n",
    "    filename : str, optional\n",
    "        filename parameter for final csv export, by default f\"custodial_sentences_by_offence_{df['year'].max()}\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Produces and saves CSV of a processed DataFrame containing offence types which received a custodial sentence, by Police Force Area, for the latest available year\n",
    "    \"\"\"\n",
    "    if filename is None:\n",
    "        filename = f\"custodial_sentences_by_offence_{df['year'].max()}\"\n",
    "    \n",
    "    my_df = df.copy()\n",
    "    \n",
    "    (my_df\n",
    "    .pipe(filterYear, 2022)\n",
    "    .pipe(filterSentence)\n",
    "    .pipe(groupAndSum, columns=['pfa', 'offence'])\n",
    "    .pipe(offenceProportions)\n",
    "    .pipe(saveData, status='processed', filename=filename)\n",
    "    )\n",
    "    \n",
    "    #Returns original DataFrame to allow for continued processing through the pipeline.\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=loadData()\n",
    "custodialSentencesByOffence(df, filename=\"TEST_FILENAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.CUSTODIAL SENTENCE LENGTHS FOR EACH PFA BY YEAR\n",
    "THIS PRODUCES THE DATA FOR FIGURE 1 IN THE PFA FACTSHEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: I HAVE AMENDED THE BIN CATEGORIES HERE FOR 6â€“LESS THAN 12 MONTHS, AND 12+ MONTHS. MAY CAUSE ISSUE IN LATER STAGES\n",
    "\n",
    "def consolidateSentenceLengths(df) -> pd.DataFrame:\n",
    "    \"\"\"Bin sentence lengths into three new distinct categories:\n",
    "        * Less than 6 months;\n",
    "        * 6 months to less than 12 months\n",
    "        * 12 months or more\n",
    "\n",
    "        12 months or more is the default value if it is not found in dict_map.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        A processed DataFrame with three distinct custodial sentence length categories based on values in `dict-map`\n",
    "    \"\"\"\n",
    "    dict_map = {\"Up to and including 1 month\": 'Less than 6 months',\n",
    "                    \"More than 1 month and up to and including 2 months\": 'Less than 6 months',\n",
    "                    \"More than 2 months and up to and including 3 months\": 'Less than 6 months',\n",
    "                    \"More than 3 months and up to 6 months\": 'Less than 6 months',\n",
    "                    \"6 months\": '6 months to less than 12 months',\n",
    "                    \"More than 6 months and up to and including 9 months\": '6 months to less than 12 months',\n",
    "                    \"More than 9 months and up to 12 months\": '6 months to less than 12 months'\n",
    "                    }\n",
    "        \n",
    "    \n",
    "    df['sentence_length'] = df['sentence_length'].map(lambda x: dict_map.get(x, \"12 months or more\"))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custodialSentenceLengths(df, filename=f\"women_cust_sentence_length_PFA_{df['year'].min()}-{df['year'].max()}\") -> pd.DataFrame:\n",
    "    \"\"\"Data processing pipeline to produce interim dataset of grouped custodial sentence lengths, by Police Force Area\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : _type_\n",
    "        _description_\n",
    "    filename : _type_, optional\n",
    "        _description_, by default f\"women_cust_sentence_length_PFA_{df['year'].min()}-{df['year'].max()}\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Produces and saves CSV of a processed DataFrame containing grouped custodial sentence lengths, by Police Force Area\n",
    "    \"\"\"\n",
    "    my_df = df.copy()\n",
    "    \n",
    "    df_processed =(\n",
    "        my_df\n",
    "        .pipe(filterSentence)\n",
    "        .pipe(consolidateSentenceLengths)\n",
    "        .pipe(groupAndSum, columns=['pfa', 'year', 'sentence_length'])\n",
    "        .pipe(saveData, status=\"interim\", filename=filename, index=False) #Query whether the status of this is interim given that it is used in production of figure 1\n",
    "    )\n",
    "    #Returning processed version of DataFrame in order to allow for further filtering by year and sentence length\n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = df.copy()\n",
    "    \n",
    "df_processed =(\n",
    "    my_df\n",
    "    .pipe(filterSentence)\n",
    "    .pipe(consolidateSentenceLengths)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=loadData()\n",
    "print('Data loaded')\n",
    "df_custodialSentences_PFA = custodialSentenceLengths(df)\n",
    "df_custodialSentences_PFA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.CUSTODIAL SENTENCES FOR EACH PFA BY YEAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS PRODUCES THREE DATASETS: \n",
    "* TOTAL NUMBER OF WOMEN SENTENCED TO CUSTODY BY PFA; AND OF THOSE \n",
    "  * SENTENCED TO LESS THAN SIX MONTHS; AND\n",
    "  * SENTENCED TO LESS THAN 12 MONTHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_custodialSentences_PFA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This following function is the starting point for producing all of the following three final datasets. It takes the DataFrame produced by `custodialSentenceLengths(df)` then filters by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterYear(df_custodialSentences_PFA, 2014, op=\"ge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterSentenceLength(df, sentence_length, column='sentence_length') -> pd.DataFrame:\n",
    "    \"\"\"DataFrame filter allowing selection of subset of data by custodial sentence length\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "\n",
    "    sentence_length : str or list-like\n",
    "        {\"Less than 6 months\", \"6 months to less than 12 months\", \"12 months or more\"}\n",
    "\n",
    "    column : str, optional\n",
    "        column name of DataFrame with custodial sentence length values, by default 'sentence_length'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        A filtered DataFrame displaying the chosen custodial sentence length\n",
    "    \"\"\"\n",
    "    mask = None\n",
    "    if type(sentence_length) == str:\n",
    "        mask = df[column] == sentence_length\n",
    "    elif type(sentence_length) == list:\n",
    "        mask = df[column].isin(sentence_length)\n",
    "    \n",
    "    filtered_df = df.loc[mask]\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregateSentences(df) -> pd.DataFrame:\n",
    "    \"\"\"Calculate total number of custodial sentences of a given length in each year, by Police Force Area\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Ensure that the DataFrame being passed to this function contains the correct sentence length(s)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        A cross-tabulated DataFrame of the total number of custodial sentences in each year, by Police Force Area\n",
    "    \"\"\"\n",
    "    \n",
    "    agg_df = pd.crosstab(index=df['pfa'], \n",
    "                columns=df['year'], \n",
    "                values=df['freq'], \n",
    "                aggfunc=sum, \n",
    "                )\n",
    "    return agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentageChange(df, periods=8) -> pd.DataFrame:\n",
    "    \"\"\"Function to calculate percentage change between the first and last year in the DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        \n",
    "    periods : int, optional\n",
    "        The total time period in years, by default 8\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        DataFrame is returned with additional column showing the percentage change as a float\n",
    "    \"\"\"\n",
    "    df.fillna(0.0).astype(int)\n",
    "    df[f'per_change_{df.columns[0]}'] = df.pct_change(axis='columns', periods=periods).dropna(axis='columns')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_custodialSentences_PFA\n",
    ".pipe(filterYear, 2014, op=\"ge\") #All custodial sentence lengths\n",
    "# .pipe(filterSentenceLength, [\"Less than 6 months\", \"6 months to less than 12 months\"]) #Less than 12 months\n",
    ".pipe(aggregateSentences)\n",
    ".pipe(percentageChange)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custodialSentenceTableProcessing(df, filename):\n",
    "    \"\"\"Processing chain to output number of custodial sentences by Police Force Area and percentage change\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        \n",
    "    filename : str\n",
    "        filename parameter for csv export\n",
    "    \"\"\"\n",
    "    (df\n",
    "    .pipe(aggregateSentences)\n",
    "    .pipe(percentageChange)\n",
    "    .pipe(saveData, status='processed', filename=f'{filename}_TEST')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custodialSentenceTableOutput(df):\n",
    "\n",
    "    df_custodialSentences_PFA = df.pipe(filterYear, 2014, op=\"ge\")\n",
    "        \n",
    "    sentence_length_dict = {'cust_sentences_total': \"\", 'cust_sentences_lt_12m': [\"Less than 6 months\", \"6 months to less than 12 months\"], 'cust_sentences_lt_6m':\"Less than 6 months\"}\n",
    "\n",
    "    for k, v in sentence_length_dict.items():\n",
    "        if v != \"\":\n",
    "            (df_custodialSentences_PFA\n",
    "            .pipe(filterSentenceLength, sentence_length=v)\n",
    "            .pipe(custodialSentenceTableProcessing, filename=f'{k}')\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            (df_custodialSentences_PFA\n",
    "            .pipe(custodialSentenceTableProcessing, filename=f'{k}')\n",
    "            )\n",
    "    \n",
    "    return \"Processing complete\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=loadData()\n",
    "print('Data loaded')\n",
    "(df\n",
    ".pipe(custodialSentenceLengths)\n",
    ".pipe(custodialSentenceTableOutput)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_custodialSentences_PFA\n",
    ".pipe(filterYear, 2014, op=\"ge\") #All custodial sentence lengths\n",
    "# .pipe(filterSentenceLength, [\"Less than 6 months\", \"6 months to less than 12 months\"]) #Less than 12 months\n",
    ".pipe(aggregateSentences)\n",
    ".pipe(percentageChange)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=loadData()\n",
    "(df\n",
    ".pipe(sentencesByPFA)\n",
    ".pipe(custodialSentencesByOffence)\n",
    ".pipe(custodialSentenceLengths)\n",
    ".pipe(custodialSentenceTableOutput)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minimal_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
